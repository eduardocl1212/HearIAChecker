{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeartCheckSound.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbXkTlIaubHgP8uCFdtnsA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPyOysWPvMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60632873-3929-4d8c-fb3c-ca05f28dcee8"
      },
      "source": [
        "!unzip heartbeat-sounds.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  heartbeat-sounds.zip\n",
            "  inflating: set_a.csv               \n",
            "  inflating: set_a/Aunlabelledtest__201012172010.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201101051105.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201101061552.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201101091156.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201101110659.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201101152256.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201101220549.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201101241434.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201102081033.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201102081045.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201102200848.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201103011036.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201103140236.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201103170122.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201103200518.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201103201314.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201103232251.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201103241336.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201104012144.wav  \n",
            "  inflating: set_a/Aunlabelledtest__2011040239.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201105011546.wav  \n",
            "  inflating: set_a/Aunlabelledtest__20110501548.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201105031730.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106010807.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106030607.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106031556.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106040930.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106061104.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106061215.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106100606.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106111419.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106120928.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106130440.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106150614.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106170857.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106171155.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106191034.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106211725.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201106212102.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108011111.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108011113.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108011116.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108011117.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222222.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222225.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222228.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222234.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222241.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222244.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222247.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222254.wav  \n",
            "  inflating: set_a/Aunlabelledtest__201108222257.wav  \n",
            "  inflating: set_a/artifact__201012172012.wav  \n",
            "  inflating: set_a/artifact__201105040918.wav  \n",
            "  inflating: set_a/artifact__201105041959.wav  \n",
            "  inflating: set_a/artifact__201105051017.wav  \n",
            "  inflating: set_a/artifact__201105060108.wav  \n",
            "  inflating: set_a/artifact__201105061143.wav  \n",
            "  inflating: set_a/artifact__201105190800.wav  \n",
            "  inflating: set_a/artifact__201105280851.wav  \n",
            "  inflating: set_a/artifact__201106010559.wav  \n",
            "  inflating: set_a/artifact__201106010602.wav  \n",
            "  inflating: set_a/artifact__201106021541.wav  \n",
            "  inflating: set_a/artifact__201106030612.wav  \n",
            "  inflating: set_a/artifact__201106031558.wav  \n",
            "  inflating: set_a/artifact__201106040722.wav  \n",
            "  inflating: set_a/artifact__201106040933.wav  \n",
            "  inflating: set_a/artifact__201106040947.wav  \n",
            "  inflating: set_a/artifact__201106041452.wav  \n",
            "  inflating: set_a/artifact__201106050353.wav  \n",
            "  inflating: set_a/artifact__201106061233.wav  \n",
            "  inflating: set_a/artifact__201106070537.wav  \n",
            "  inflating: set_a/artifact__201106070949.wav  \n",
            "  inflating: set_a/artifact__201106101314.wav  \n",
            "  inflating: set_a/artifact__201106101955.wav  \n",
            "  inflating: set_a/artifact__201106110909.wav  \n",
            "  inflating: set_a/artifact__201106111119.wav  \n",
            "  inflating: set_a/artifact__201106121242.wav  \n",
            "  inflating: set_a/artifact__201106121445.wav  \n",
            "  inflating: set_a/artifact__201106131834.wav  \n",
            "  inflating: set_a/artifact__201106131835.wav  \n",
            "  inflating: set_a/artifact__201106141701.wav  \n",
            "  inflating: set_a/artifact__201106161016.wav  \n",
            "  inflating: set_a/artifact__201106161019.wav  \n",
            "  inflating: set_a/artifact__201106161219.wav  \n",
            "  inflating: set_a/artifact__201106171003.wav  \n",
            "  inflating: set_a/artifact__201106190520.wav  \n",
            "  inflating: set_a/artifact__201106211041.wav  \n",
            "  inflating: set_a/artifact__201106211430.wav  \n",
            "  inflating: set_a/artifact__201106212112.wav  \n",
            "  inflating: set_a/artifact__201106220340.wav  \n",
            "  inflating: set_a/artifact__201106221254.wav  \n",
            "  inflating: set_a/extrahls__201101070953.wav  \n",
            "  inflating: set_a/extrahls__201101091153.wav  \n",
            "  inflating: set_a/extrahls__201101152255.wav  \n",
            "  inflating: set_a/extrahls__201101160804.wav  \n",
            "  inflating: set_a/extrahls__201101160808.wav  \n",
            "  inflating: set_a/extrahls__201101161027.wav  \n",
            "  inflating: set_a/extrahls__201101241423.wav  \n",
            "  inflating: set_a/extrahls__201101241433.wav  \n",
            "  inflating: set_a/extrahls__201102070251.wav  \n",
            "  inflating: set_a/extrahls__201102071835.wav  \n",
            "  inflating: set_a/extrahls__201102241217.wav  \n",
            "  inflating: set_a/extrahls__201103150114.wav  \n",
            "  inflating: set_a/extrahls__201103170134.wav  \n",
            "  inflating: set_a/extrahls__201103182227.wav  \n",
            "  inflating: set_a/extrahls__201103200218.wav  \n",
            "  inflating: set_a/extrahls__201104021355.wav  \n",
            "  inflating: set_a/extrahls__201104140118.wav  \n",
            "  inflating: set_a/extrahls__201104270458.wav  \n",
            "  inflating: set_a/extrahls__201104270459.wav  \n",
            "  inflating: set_a/murmur__201101051104.wav  \n",
            "  inflating: set_a/murmur__201101051108.wav  \n",
            "  inflating: set_a/murmur__201101051114.wav  \n",
            "  inflating: set_a/murmur__201101180902.wav  \n",
            "  inflating: set_a/murmur__201102051443.wav  \n",
            "  inflating: set_a/murmur__201102052338.wav  \n",
            "  inflating: set_a/murmur__201103291548.wav  \n",
            "  inflating: set_a/murmur__201104021355.wav  \n",
            "  inflating: set_a/murmur__201104241315.wav  \n",
            "  inflating: set_a/murmur__201104291843.wav  \n",
            "  inflating: set_a/murmur__201106141148.wav  \n",
            "  inflating: set_a/murmur__201108222221.wav  \n",
            "  inflating: set_a/murmur__201108222223.wav  \n",
            "  inflating: set_a/murmur__201108222224.wav  \n",
            "  inflating: set_a/murmur__201108222226.wav  \n",
            "  inflating: set_a/murmur__201108222227.wav  \n",
            "  inflating: set_a/murmur__201108222231.wav  \n",
            "  inflating: set_a/murmur__201108222232.wav  \n",
            "  inflating: set_a/murmur__201108222233.wav  \n",
            "  inflating: set_a/murmur__201108222235.wav  \n",
            "  inflating: set_a/murmur__201108222236.wav  \n",
            "  inflating: set_a/murmur__201108222237.wav  \n",
            "  inflating: set_a/murmur__201108222238.wav  \n",
            "  inflating: set_a/murmur__201108222242.wav  \n",
            "  inflating: set_a/murmur__201108222243.wav  \n",
            "  inflating: set_a/murmur__201108222245.wav  \n",
            "  inflating: set_a/murmur__201108222246.wav  \n",
            "  inflating: set_a/murmur__201108222248.wav  \n",
            "  inflating: set_a/murmur__201108222251.wav  \n",
            "  inflating: set_a/murmur__201108222252.wav  \n",
            "  inflating: set_a/murmur__201108222253.wav  \n",
            "  inflating: set_a/murmur__201108222255.wav  \n",
            "  inflating: set_a/murmur__201108222256.wav  \n",
            "  inflating: set_a/murmur__201108222258.wav  \n",
            "  inflating: set_a/normal__201101070538.wav  \n",
            "  inflating: set_a/normal__201101151127.wav  \n",
            "  inflating: set_a/normal__201102081152.wav  \n",
            "  inflating: set_a/normal__201102081321.wav  \n",
            "  inflating: set_a/normal__201102201230.wav  \n",
            "  inflating: set_a/normal__201102260502.wav  \n",
            "  inflating: set_a/normal__201102270940.wav  \n",
            "  inflating: set_a/normal__201103090635.wav  \n",
            "  inflating: set_a/normal__201103101140.wav  \n",
            "  inflating: set_a/normal__201103140132.wav  \n",
            "  inflating: set_a/normal__201103140135.wav  \n",
            "  inflating: set_a/normal__201103140822.wav  \n",
            "  inflating: set_a/normal__201103151912.wav  \n",
            "  inflating: set_a/normal__201103170121.wav  \n",
            "  inflating: set_a/normal__201103221214.wav  \n",
            "  inflating: set_a/normal__201104122156.wav  \n",
            "  inflating: set_a/normal__201104141251.wav  \n",
            "  inflating: set_a/normal__201105011626.wav  \n",
            "  inflating: set_a/normal__201105021654.wav  \n",
            "  inflating: set_a/normal__201105021804.wav  \n",
            "  inflating: set_a/normal__201105151450.wav  \n",
            "  inflating: set_a/normal__201106111136.wav  \n",
            "  inflating: set_a/normal__201106141148.wav  \n",
            "  inflating: set_a/normal__201106151236.wav  \n",
            "  inflating: set_a/normal__201106210943.wav  \n",
            "  inflating: set_a/normal__201106221418.wav  \n",
            "  inflating: set_a/normal__201106221450.wav  \n",
            "  inflating: set_a/normal__201108011112.wav  \n",
            "  inflating: set_a/normal__201108011114.wav  \n",
            "  inflating: set_a/normal__201108011115.wav  \n",
            "  inflating: set_a/normal__201108011118.wav  \n",
            "  inflating: set_a_timing.csv        \n",
            "  inflating: set_b.csv               \n",
            "  inflating: set_b/Bunlabelledtest__101_1305030823364_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__101_1305030823364_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__101_1305030823364_F.wav  \n",
            "  inflating: set_b/Bunlabelledtest__103_1305031931979_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__103_1305031931979_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__105_1305033453095_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__105_1305033453095_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__106_1306776721273_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__106_1306776721273_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__107_1305654946865_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__107_1305654946865_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__108_1305654420093_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__109_1305653646620_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__109_1305653646620_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__109_1305653972028_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__109_1305653972028_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__110_1305655332337_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__112_1306243000964_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__113_1306244002866_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__115_1306259437619_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__116_1306258689913_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__117_1306262456650_B1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__118_1306262335509_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__118_1306262335509_A1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__118_1306262335509_C2.wav  \n",
            "  inflating: set_b/Bunlabelledtest__121_1306263877235_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__122_1306325762831_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__122_1306325762831_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__123_1306331925797_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__123_1306331925797_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__125_1306332456645_B2.wav  \n",
            "  inflating: set_b/Bunlabelledtest__126_1306777102824_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__126_1306777102824_D1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__127_1306764300147_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__128_1306344005749_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__129_1306344506305_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__130_1306347376079_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__132_1306758754432_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__132_1306758754432_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__132_1306758754432_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__134_1306428161797_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__134_1306428161797_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__135_1306428972976_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__136_1306429977501_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__136_1306429977501_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__137_1306764999211_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__137_1306764999211_B1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__137_1306764999211_D2.wav  \n",
            "  inflating: set_b/Bunlabelledtest__138_1306762146980_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__139_1306519274653_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__139_1306519274653_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__141_1306520154450_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__141_1306520154450_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__142_1306763049574_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__143_1306763822290_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__144_1306522408528_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__145_1307987561278_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__145_1307987561278_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__146_1306778707532_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__146_1306778707532_D31.wav  \n",
            "  inflating: set_b/Bunlabelledtest__147_1306523973811_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__148_1306768801551_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__148_1306768801551_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__148_1306768801551_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__149_1306776016110_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__150_1306776340746_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__151_1306779785624_A1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__152_1306779561195_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__152_1306779561195_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__152_1306779561195_D1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__153_1306848820671_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__154_1306935608852_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__154_1306935608852_A2.wav  \n",
            "  inflating: set_b/Bunlabelledtest__154_1306935608852_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__154_1306935608852_D1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__155_1306935902813_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__155_1306935902813_B2.wav  \n",
            "  inflating: set_b/Bunlabelledtest__155_1306935902813_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__156_1306936373241_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__156_1306936373241_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__157_1306937583792_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__159_1307018640315_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__159_1307018640315_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__159_1307018640315_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__160_1307100683334_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__161_1307101199321_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__162_1307101835989_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__163_1307104470471_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__163_1307104470471_B1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__163_1307104470471_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__164_1307106095995_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__165_1307109069581_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__167_1307111318050_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__167_1307111318050_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__169_1307970398039_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__169_1307970398039_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__170_1307970562729_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__171_1307971016233_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__171_1307971016233_F.wav  \n",
            "  inflating: set_b/Bunlabelledtest__172_1307971284351_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__172_1307971284351_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__173_1307973611151_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__174_1307987737137_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__175_1307987962616_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__176_1307988171173_A1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__176_1307988171173_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__176_1307988171173_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__177_1307989650056_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__178_1307989887769_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__179_1307990076841_D1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__180_1307990956284_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__180_1307990956284_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__181_1308052613891_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__184_1308073010307_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__186_1308073648738_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__186_1308073648738_D1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__187_1308073994223_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__189_1308075231945_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__189_1308075231945_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__191_1308077299430_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__191_1308077299430_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__193_1308078104592_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__193_1308078104592_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__194_1308139824187_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__195_1308140095331_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__196_1308141034858_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__197_1308141235553_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__200_1308144251434_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__201_1308144942432_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__202_1308145175747_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__203_1308162026258_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__204_1308159229275_B1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__206_1308159601959_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__207_1308159792607_B3.wav  \n",
            "  inflating: set_b/Bunlabelledtest__209_1308162216750_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__209_1308162216750_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__210_1308162935880_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__212_1308245076477_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__213_1308245263936_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__214_1308245489717_A1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__215_1308245664733_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__216_1308245839516_B1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__217_1308246111629_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__217_1308246111629_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__217_1308246111629_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__220_1308250132896_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__222_1308336218979_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__227_1308594233667_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__229_1308594979317_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__231_1308748318393_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__231_1308748318393_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__232_1308748524018_A1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__232_1308748524018_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__235_1308749032454_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__235_1308749032454_D1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__237_1308750231222_C1.wav  \n",
            "  inflating: set_b/Bunlabelledtest__239_1309195730333_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__240_1309196119795_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__242_1309197394064_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__242_1309197394064_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__243_1309197760898_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__245_1309198844065_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__245_1309200438094_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__248_1309201683806_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__248_1309201683806_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__254_1309350589009_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__255_1309351210897_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__259_1309352630271_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__260_1309353164458_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__262_1309355283807_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__264_1309356143724_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__268_1309368960960_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__268_1309368960960_E.wav  \n",
            "  inflating: set_b/Bunlabelledtest__270_1309369533040_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__271_1309369876160_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__272_1309370164386_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__274_1311075637574_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__278_1311163365896_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__278_1311163365896_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__280_1311165195344_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__281_1311165683454_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__282_1311166081161_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__284_1311168471850_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__286_1311170606028_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__287_1311170903290_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__288_1311164615284_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__290_1311182875320_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__293_1311680805936_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__293_1311680805936_B2.wav  \n",
            "  inflating: set_b/Bunlabelledtest__294_1311681084248_D.wav  \n",
            "  inflating: set_b/Bunlabelledtest__296_1311682952647_A.wav  \n",
            "  inflating: set_b/Bunlabelledtest__296_1311682952647_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__300_1311772096120_B.wav  \n",
            "  inflating: set_b/Bunlabelledtest__300_1311772096120_C.wav  \n",
            "  inflating: set_b/Bunlabelledtest__300_1311772096120_D.wav  \n",
            "  inflating: set_b/extrastole__127_1306764300147_C2.wav  \n",
            "  inflating: set_b/extrastole__128_1306344005749_A.wav  \n",
            "  inflating: set_b/extrastole__130_1306347376079_D.wav  \n",
            "  inflating: set_b/extrastole__134_1306428161797_C1.wav  \n",
            "  inflating: set_b/extrastole__138_1306762146980_B.wav  \n",
            "  inflating: set_b/extrastole__140_1306519735121_D.wav  \n",
            "  inflating: set_b/extrastole__144_1306522408528_B.wav  \n",
            "  inflating: set_b/extrastole__144_1306522408528_B1.wav  \n",
            "  inflating: set_b/extrastole__148_1306768801551_B.wav  \n",
            "  inflating: set_b/extrastole__151_1306779785624_B.wav  \n",
            "  inflating: set_b/extrastole__153_1306848820671_C.wav  \n",
            "  inflating: set_b/extrastole__154_1306935608852_D2.wav  \n",
            "  inflating: set_b/extrastole__163_1307104470471_C.wav  \n",
            "  inflating: set_b/extrastole__179_1307990076841_C.wav  \n",
            "  inflating: set_b/extrastole__184_1308073010307_A.wav  \n",
            "  inflating: set_b/extrastole__190_1308076920011_C.wav  \n",
            "  inflating: set_b/extrastole__191_1308077299430_A.wav  \n",
            "  inflating: set_b/extrastole__194_1308139824187_B.wav  \n",
            "  inflating: set_b/extrastole__198_1308141739338_B.wav  \n",
            "  inflating: set_b/extrastole__198_1308141739338_B1.wav  \n",
            "  inflating: set_b/extrastole__202_1308145175747_C1.wav  \n",
            "  inflating: set_b/extrastole__202_1308145175747_C2.wav  \n",
            "  inflating: set_b/extrastole__207_1308159792607_B.wav  \n",
            "  inflating: set_b/extrastole__207_1308159792607_B1.wav  \n",
            "  inflating: set_b/extrastole__209_1308162216750_D.wav  \n",
            "  inflating: set_b/extrastole__210_1308162935880_C.wav  \n",
            "  inflating: set_b/extrastole__213_1308245263936_D.wav  \n",
            "  inflating: set_b/extrastole__215_1308245664733_B.wav  \n",
            "  inflating: set_b/extrastole__215_1308245664733_B1.wav  \n",
            "  inflating: set_b/extrastole__216_1308245839516_A.wav  \n",
            "  inflating: set_b/extrastole__216_1308245839516_B.wav  \n",
            "  inflating: set_b/extrastole__220_1308250132896_B.wav  \n",
            "  inflating: set_b/extrastole__224_1308337157445_B.wav  \n",
            "  inflating: set_b/extrastole__229_1308594979317_B.wav  \n",
            "  inflating: set_b/extrastole__235_1308749032454_B.wav  \n",
            "  inflating: set_b/extrastole__237_1308750231222_A.wav  \n",
            "  inflating: set_b/extrastole__237_1308750231222_C.wav  \n",
            "  inflating: set_b/extrastole__249_1309202052376_C.wav  \n",
            "  inflating: set_b/extrastole__253_1309350256198_B.wav  \n",
            "  inflating: set_b/extrastole__261_1309353556003_C.wav  \n",
            "  inflating: set_b/extrastole__265_1309367698923_C.wav  \n",
            "  inflating: set_b/extrastole__274_1311075637574_A.wav  \n",
            "  inflating: set_b/extrastole__275_1310990852160_B.wav  \n",
            "  inflating: set_b/extrastole__286_1311170606028_D.wav  \n",
            "  inflating: set_b/extrastole__294_1311681084248_C.wav  \n",
            "  inflating: set_b/extrastole__298_1311685888900_C.wav  \n",
            "  inflating: set_b/murmur__112_1306243000964_A.wav  \n",
            "  inflating: set_b/murmur__112_1306243000964_B.wav  \n",
            "  inflating: set_b/murmur__112_1306243000964_D.wav  \n",
            "  inflating: set_b/murmur__116_1306258689913_A.wav  \n",
            "  inflating: set_b/murmur__116_1306258689913_C.wav  \n",
            "  inflating: set_b/murmur__116_1306258689913_D.wav  \n",
            "  inflating: set_b/murmur__122_1306325762831_C.wav  \n",
            "  inflating: set_b/murmur__122_1306325762831_D.wav  \n",
            "  inflating: set_b/murmur__156_1306936373241_B.wav  \n",
            "  inflating: set_b/murmur__160_1307100683334_A.wav  \n",
            "  inflating: set_b/murmur__160_1307100683334_B.wav  \n",
            "  inflating: set_b/murmur__161_1307101199321_A.wav  \n",
            "  inflating: set_b/murmur__162_1307101835989_A.wav  \n",
            "  inflating: set_b/murmur__162_1307101835989_B.wav  \n",
            "  inflating: set_b/murmur__164_1307106095995_B.wav  \n",
            "  inflating: set_b/murmur__164_1307106095995_C.wav  \n",
            "  inflating: set_b/murmur__165_1307109069581_C.wav  \n",
            "  inflating: set_b/murmur__165_1307109069581_C2.wav  \n",
            "  inflating: set_b/murmur__171_1307971016233_D.wav  \n",
            "  inflating: set_b/murmur__171_1307971016233_D1.wav  \n",
            "  inflating: set_b/murmur__171_1307971016233_E.wav  \n",
            "  inflating: set_b/murmur__185_1308073325396_B.wav  \n",
            "  inflating: set_b/murmur__185_1308073325396_C.wav  \n",
            "  inflating: set_b/murmur__193_1308078104592_B.wav  \n",
            "  inflating: set_b/murmur__193_1308078104592_C.wav  \n",
            "  inflating: set_b/murmur__193_1308078104592_C1.wav  \n",
            "  inflating: set_b/murmur__195_1308140095331_A.wav  \n",
            "  inflating: set_b/murmur__195_1308140095331_C.wav  \n",
            "  inflating: set_b/murmur__195_1308140095331_C1.wav  \n",
            "  inflating: set_b/murmur__196_1308141034858_B.wav  \n",
            "  inflating: set_b/murmur__196_1308141034858_C.wav  \n",
            "  inflating: set_b/murmur__197_1308141235553_A.wav  \n",
            "  inflating: set_b/murmur__197_1308141235553_C.wav  \n",
            "  inflating: set_b/murmur__197_1308141235553_D.wav  \n",
            "  inflating: set_b/murmur__200_1308144251434_C.wav  \n",
            "  inflating: set_b/murmur__200_1308144251434_D.wav  \n",
            "  inflating: set_b/murmur__203_1308162026258_B.wav  \n",
            "  inflating: set_b/murmur__203_1308162026258_C1.wav  \n",
            "  inflating: set_b/murmur__203_1308162026258_D.wav  \n",
            "  inflating: set_b/murmur__204_1308159229275_B.wav  \n",
            "  inflating: set_b/murmur__211_1308163238707_C.wav  \n",
            "  inflating: set_b/murmur__223_1308337062581_D.wav  \n",
            "  inflating: set_b/murmur__239_1309195730333_B.wav  \n",
            "  inflating: set_b/murmur__239_1309195730333_C.wav  \n",
            "  inflating: set_b/murmur__240_1309196119795_B.wav  \n",
            "  inflating: set_b/murmur__240_1309196119795_C.wav  \n",
            "  inflating: set_b/murmur__240_1309201366049_B.wav  \n",
            "  inflating: set_b/murmur__242_1309197394064_B.wav  \n",
            "  inflating: set_b/murmur__242_1309197394064_D.wav  \n",
            "  inflating: set_b/murmur__244_1309198148498_B.wav  \n",
            "  inflating: set_b/murmur__245_1309200438094_B.wav  \n",
            "  inflating: set_b/murmur__248_1309201683806_A.wav  \n",
            "  inflating: set_b/murmur__248_1309201683806_C.wav  \n",
            "  inflating: set_b/murmur__254_1309350589009_A.wav  \n",
            "  inflating: set_b/murmur__254_1309350589009_A1.wav  \n",
            "  inflating: set_b/murmur__254_1309350589009_C.wav  \n",
            "  inflating: set_b/murmur__254_1309350589009_D.wav  \n",
            "  inflating: set_b/murmur__276_1311162716489_C.wav  \n",
            "  inflating: set_b/murmur__281_1311165683454_A.wav  \n",
            "  inflating: set_b/murmur__281_1311165683454_B.wav  \n",
            "  inflating: set_b/murmur__281_1311165683454_D.wav  \n",
            "  inflating: set_b/murmur__287_1311170903290_C.wav  \n",
            "  inflating: set_b/murmur__288_1311164615284_D.wav  \n",
            "  inflating: set_b/murmur__292_1311185449649_B.wav  \n",
            "  inflating: set_b/murmur__292_1311185449649_C.wav  \n",
            "  inflating: set_b/murmur__293_1311680805936_B1.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_135_1306428972976_A.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_135_1306428972976_B.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_135_1306428972976_C.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_156_1306936373241_A.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_156_1306936373241_B1.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_160_1307100683334_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_161_1307101199321_B.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_161_1307101199321_C.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_162_1307101835989_B_1.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_162_1307101835989_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_164_1307106095995_C1.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_165_1307109069581_A.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_165_1307109069581_C1.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_165_1307109069581_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_171_1307971016233_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_171_1307971016233_F.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_185_1308073325396_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_200_1308144251434_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_231_1308748318393_A.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_240_1309201366049_C.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_240_1309201366049_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_243_1309197760898_B.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_243_1309197760898_C.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_272_1309370164386_C.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_288_1311164615284_B1.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_288_1311164615284_C.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_292_1311185449649_D.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_293_1311680805936_C.wav  \n",
            "  inflating: set_b/murmur_noisymurmur_293_1311680805936_D.wav  \n",
            "  inflating: set_b/normal__103_1305031931979_B.wav  \n",
            "  inflating: set_b/normal__103_1305031931979_D1.wav  \n",
            "  inflating: set_b/normal__103_1305031931979_D2.wav  \n",
            "  inflating: set_b/normal__103_1305031931979_D3.wav  \n",
            "  inflating: set_b/normal__106_1306776721273_B1.wav  \n",
            "  inflating: set_b/normal__106_1306776721273_C1.wav  \n",
            "  inflating: set_b/normal__106_1306776721273_C2.wav  \n",
            "  inflating: set_b/normal__106_1306776721273_D1.wav  \n",
            "  inflating: set_b/normal__106_1306776721273_D2.wav  \n",
            "  inflating: set_b/normal__107_1305654946865_C1.wav  \n",
            "  inflating: set_b/normal__109_1305653646620_C.wav  \n",
            "  inflating: set_b/normal__113_1306244002866_D.wav  \n",
            "  inflating: set_b/normal__115_1306259437619_C.wav  \n",
            "  inflating: set_b/normal__117_1306262456650_B.wav  \n",
            "  inflating: set_b/normal__125_1306332456645_B.wav  \n",
            "  inflating: set_b/normal__126_1306777102824_B.wav  \n",
            "  inflating: set_b/normal__126_1306777102824_C.wav  \n",
            "  inflating: set_b/normal__126_1306777102824_D.wav  \n",
            "  inflating: set_b/normal__127_1306764300147_A.wav  \n",
            "  inflating: set_b/normal__127_1306764300147_B.wav  \n",
            "  inflating: set_b/normal__127_1306764300147_C1.wav  \n",
            "  inflating: set_b/normal__128_1306344005749_B.wav  \n",
            "  inflating: set_b/normal__128_1306344005749_D.wav  \n",
            "  inflating: set_b/normal__128_1306344005749_D1.wav  \n",
            "  inflating: set_b/normal__129_1306344506305_B1.wav  \n",
            "  inflating: set_b/normal__129_1306344506305_D.wav  \n",
            "  inflating: set_b/normal__129_1306344506305_D1.wav  \n",
            "  inflating: set_b/normal__133_1306759619127_A.wav  \n",
            "  inflating: set_b/normal__133_1306759619127_B.wav  \n",
            "  inflating: set_b/normal__133_1306759619127_D.wav  \n",
            "  inflating: set_b/normal__134_1306428161797_C.wav  \n",
            "  inflating: set_b/normal__134_1306428161797_C2.wav  \n",
            "  inflating: set_b/normal__134_1306428161797_D.wav  \n",
            "  inflating: set_b/normal__137_1306764999211_C.wav  \n",
            "  inflating: set_b/normal__137_1306764999211_D.wav  \n",
            "  inflating: set_b/normal__139_1306519274653_A.wav  \n",
            "  inflating: set_b/normal__140_1306519735121_A.wav  \n",
            "  inflating: set_b/normal__140_1306519735121_B.wav  \n",
            "  inflating: set_b/normal__140_1306519735121_D1.wav  \n",
            "  inflating: set_b/normal__141_1306520154450_B.wav  \n",
            "  inflating: set_b/normal__141_1306520154450_C.wav  \n",
            "  inflating: set_b/normal__143_1306763822290_B.wav  \n",
            "  inflating: set_b/normal__143_1306763822290_C.wav  \n",
            "  inflating: set_b/normal__145_1307987561278_B.wav  \n",
            "  inflating: set_b/normal__145_1307987561278_C.wav  \n",
            "  inflating: set_b/normal__146_1306778707532_A.wav  \n",
            "  inflating: set_b/normal__146_1306778707532_B.wav  \n",
            "  inflating: set_b/normal__146_1306778707532_D1.wav  \n",
            "  inflating: set_b/normal__146_1306778707532_D2.wav  \n",
            "  inflating: set_b/normal__146_1306778707532_D3.wav  \n",
            "  inflating: set_b/normal__146_1306778707532_D4.wav  \n",
            "  inflating: set_b/normal__147_1306523973811_A.wav  \n",
            "  inflating: set_b/normal__147_1306523973811_C.wav  \n",
            "  inflating: set_b/normal__148_1306768801551_C1.wav  \n",
            "  inflating: set_b/normal__148_1306768801551_D2.wav  \n",
            "  inflating: set_b/normal__149_1306776016110_B.wav  \n",
            "  inflating: set_b/normal__149_1306776016110_C1.wav  \n",
            "  inflating: set_b/normal__150_1306776340746_B.wav  \n",
            "  inflating: set_b/normal__150_1306776340746_C.wav  \n",
            "  inflating: set_b/normal__151_1306779785624_A.wav  \n",
            "  inflating: set_b/normal__151_1306779785624_D.wav  \n",
            "  inflating: set_b/normal__152_1306779561195_B1.wav  \n",
            "  inflating: set_b/normal__152_1306779561195_C1.wav  \n",
            "  inflating: set_b/normal__152_1306779561195_D.wav  \n",
            "  inflating: set_b/normal__153_1306848820671_A.wav  \n",
            "  inflating: set_b/normal__153_1306848820671_B.wav  \n",
            "  inflating: set_b/normal__153_1306848820671_B1.wav  \n",
            "  inflating: set_b/normal__153_1306848820671_D1.wav  \n",
            "  inflating: set_b/normal__154_1306935608852_A1.wav  \n",
            "  inflating: set_b/normal__154_1306935608852_B.wav  \n",
            "  inflating: set_b/normal__154_1306935608852_B1.wav  \n",
            "  inflating: set_b/normal__154_1306935608852_D.wav  \n",
            "  inflating: set_b/normal__155_1306935902813_B1.wav  \n",
            "  inflating: set_b/normal__158_1306947254705_B2.wav  \n",
            "  inflating: set_b/normal__159_1307018640315_A.wav  \n",
            "  inflating: set_b/normal__159_1307018640315_B1.wav  \n",
            "  inflating: set_b/normal__159_1307018640315_B2.wav  \n",
            "  inflating: set_b/normal__159_1307018640315_C1.wav  \n",
            "  inflating: set_b/normal__167_1307111318050_A.wav  \n",
            "  inflating: set_b/normal__167_1307111318050_C.wav  \n",
            "  inflating: set_b/normal__168_1307970069434_A.wav  \n",
            "  inflating: set_b/normal__168_1307970069434_A2.wav  \n",
            "  inflating: set_b/normal__169_1307970398039_C.wav  \n",
            "  inflating: set_b/normal__170_1307970562729_A.wav  \n",
            "  inflating: set_b/normal__170_1307970562729_B.wav  \n",
            "  inflating: set_b/normal__170_1307970562729_C.wav  \n",
            "  inflating: set_b/normal__172_1307971284351_B.wav  \n",
            "  inflating: set_b/normal__172_1307971284351_B1.wav  \n",
            "  inflating: set_b/normal__173_1307973611151_B.wav  \n",
            "  inflating: set_b/normal__173_1307973611151_C.wav  \n",
            "  inflating: set_b/normal__174_1307987737137_B.wav  \n",
            "  inflating: set_b/normal__174_1307987737137_B1.wav  \n",
            "  inflating: set_b/normal__175_1307987962616_B.wav  \n",
            "  inflating: set_b/normal__175_1307987962616_B1.wav  \n",
            "  inflating: set_b/normal__175_1307987962616_D.wav  \n",
            "  inflating: set_b/normal__176_1307988171173_A.wav  \n",
            "  inflating: set_b/normal__176_1307988171173_B.wav  \n",
            "  inflating: set_b/normal__176_1307988171173_B1.wav  \n",
            "  inflating: set_b/normal__177_1307989650056_A1.wav  \n",
            "  inflating: set_b/normal__177_1307989650056_B.wav  \n",
            "  inflating: set_b/normal__177_1307989650056_D.wav  \n",
            "  inflating: set_b/normal__177_1307989650056_D1.wav  \n",
            "  inflating: set_b/normal__178_1307989887769_B.wav  \n",
            "  inflating: set_b/normal__178_1307989887769_D.wav  \n",
            "  inflating: set_b/normal__179_1307990076841_B.wav  \n",
            "  inflating: set_b/normal__179_1307990076841_D.wav  \n",
            "  inflating: set_b/normal__180_1307990956284_A.wav  \n",
            "  inflating: set_b/normal__180_1307990956284_C.wav  \n",
            "  inflating: set_b/normal__181_1308052613891_B.wav  \n",
            "  inflating: set_b/normal__181_1308052613891_D.wav  \n",
            "  inflating: set_b/normal__183_1308072703477_B.wav  \n",
            "  inflating: set_b/normal__183_1308072703477_C.wav  \n",
            "  inflating: set_b/normal__184_1308073010307_B.wav  \n",
            "  inflating: set_b/normal__184_1308073010307_D.wav  \n",
            "  inflating: set_b/normal__186_1308073648738_C1.wav  \n",
            "  inflating: set_b/normal__186_1308073648738_D.wav  \n",
            "  inflating: set_b/normal__188_1308074301731_C.wav  \n",
            "  inflating: set_b/normal__188_1308074301731_D.wav  \n",
            "  inflating: set_b/normal__190_1308076920011_C1.wav  \n",
            "  inflating: set_b/normal__190_1308076920011_D.wav  \n",
            "  inflating: set_b/normal__191_1308077299430_B.wav  \n",
            "  inflating: set_b/normal__194_1308139824187_A.wav  \n",
            "  inflating: set_b/normal__194_1308139824187_A1.wav  \n",
            "  inflating: set_b/normal__198_1308141739338_C.wav  \n",
            "  inflating: set_b/normal__201_1308144942432_A.wav  \n",
            "  inflating: set_b/normal__201_1308144942432_A1.wav  \n",
            "  inflating: set_b/normal__202_1308145175747_C.wav  \n",
            "  inflating: set_b/normal__202_1308145175747_D.wav  \n",
            "  inflating: set_b/normal__204_1308159229275_C.wav  \n",
            "  inflating: set_b/normal__204_1308159229275_D.wav  \n",
            "  inflating: set_b/normal__206_1308159601959_C.wav  \n",
            "  inflating: set_b/normal__207_1308159792607_C.wav  \n",
            "  inflating: set_b/normal__208_1308159994503_C.wav  \n",
            "  inflating: set_b/normal__209_1308162216750_A.wav  \n",
            "  inflating: set_b/normal__209_1308162216750_A1.wav  \n",
            "  inflating: set_b/normal__210_1308162935880_B.wav  \n",
            "  inflating: set_b/normal__210_1308162935880_B1.wav  \n",
            "  inflating: set_b/normal__210_1308162935880_D1.wav  \n",
            "  inflating: set_b/normal__210_1308162935880_D2.wav  \n",
            "  inflating: set_b/normal__213_1308245263936_C.wav  \n",
            "  inflating: set_b/normal__214_1308245489717_A.wav  \n",
            "  inflating: set_b/normal__215_1308245664733_C.wav  \n",
            "  inflating: set_b/normal__215_1308245664733_C1.wav  \n",
            "  inflating: set_b/normal__216_1308245839516_C.wav  \n",
            "  inflating: set_b/normal__217_1308246111629_C.wav  \n",
            "  inflating: set_b/normal__217_1308246111629_C1.wav  \n",
            "  inflating: set_b/normal__218_1308246311449_C.wav  \n",
            "  inflating: set_b/normal__218_1308246311449_C1.wav  \n",
            "  inflating: set_b/normal__220_1308250132896_C.wav  \n",
            "  inflating: set_b/normal__220_1308250132896_D.wav  \n",
            "  inflating: set_b/normal__224_1308337157445_C.wav  \n",
            "  inflating: set_b/normal__227_1308594233667_B.wav  \n",
            "  inflating: set_b/normal__227_1308594233667_C.wav  \n",
            "  inflating: set_b/normal__230_1308595300880_B.wav  \n",
            "  inflating: set_b/normal__230_1308595300880_C.wav  \n",
            "  inflating: set_b/normal__232_1308748524018_A.wav  \n",
            "  inflating: set_b/normal__232_1308748524018_B.wav  \n",
            "  inflating: set_b/normal__232_1308748524018_B1.wav  \n",
            "  inflating: set_b/normal__232_1308748524018_C.wav  \n",
            "  inflating: set_b/normal__232_1308748524018_D1.wav  \n",
            "  inflating: set_b/normal__235_1308749032454_C.wav  \n",
            "  inflating: set_b/normal__235_1308749032454_D.wav  \n",
            "  inflating: set_b/normal__237_1308750231222_C.wav  \n",
            "  inflating: set_b/normal__238_1309194586293_A.wav  \n",
            "  inflating: set_b/normal__238_1309194586293_B.wav  \n",
            "  inflating: set_b/normal__250_1309202496494_A.wav  \n",
            "  inflating: set_b/normal__250_1309202496494_B.wav  \n",
            "  inflating: set_b/normal__252_1309203336604_B.wav  \n",
            "  inflating: set_b/normal__256_1309351470137_A.wav  \n",
            "  inflating: set_b/normal__258_1309352253234_C.wav  \n",
            "  inflating: set_b/normal__260_1309353164458_C.wav  \n",
            "  inflating: set_b/normal__261_1309353556003_B.wav  \n",
            "  inflating: set_b/normal__262_1309355283807_A.wav  \n",
            "  inflating: set_b/normal__267_1309368735165_A.wav  \n",
            "  inflating: set_b/normal__270_1309369533040_C.wav  \n",
            "  inflating: set_b/normal__273_1309370841191_B.wav  \n",
            "  inflating: set_b/normal__274_1311075637574_A1.wav  \n",
            "  inflating: set_b/normal__274_1311075637574_B.wav  \n",
            "  inflating: set_b/normal__274_1311075637574_B1.wav  \n",
            "  inflating: set_b/normal__274_1311075637574_D.wav  \n",
            "  inflating: set_b/normal__278_1311163365896_A.wav  \n",
            "  inflating: set_b/normal__278_1311163365896_A1.wav  \n",
            "  inflating: set_b/normal__280_1311165195344_A.wav  \n",
            "  inflating: set_b/normal__282_1311166081161_C.wav  \n",
            "  inflating: set_b/normal__283_1311167409239_A.wav  \n",
            "  inflating: set_b/normal__286_1311170606028_A.wav  \n",
            "  inflating: set_b/normal__286_1311170606028_A1.wav  \n",
            "  inflating: set_b/normal__286_1311170606028_B1.wav  \n",
            "  inflating: set_b/normal__286_1311170606028_C.wav  \n",
            "  inflating: set_b/normal__290_1311182875320_A.wav  \n",
            "  inflating: set_b/normal__291_1311185210672_A.wav  \n",
            "  inflating: set_b/normal__294_1311681084248_A.wav  \n",
            "  inflating: set_b/normal__294_1311681084248_B.wav  \n",
            "  inflating: set_b/normal__294_1311681084248_D1.wav  \n",
            "  inflating: set_b/normal__295_1311682673157_D.wav  \n",
            "  inflating: set_b/normal__296_1311682952647_A1.wav  \n",
            "  inflating: set_b/normal__296_1311682952647_A2.wav  \n",
            "  inflating: set_b/normal__298_1311685888900_B.wav  \n",
            "  inflating: set_b/normal__299_1311770522820_C.wav  \n",
            "  inflating: set_b/normal__300_1311772096120_C1.wav  \n",
            "  inflating: set_b/normal_noisynormal_101_1305030823364_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_101_1305030823364_E.wav  \n",
            "  inflating: set_b/normal_noisynormal_104_1305032492469_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_105_1305033453095_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_105_1305033453095_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_106_1306776721273_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_107_1305654946865_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_108_1305654420093_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_108_1305654420093_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_109_1305653646620_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_109_1305653972028_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_109_1305653972028_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_109_1305653972028_E.wav  \n",
            "  inflating: set_b/normal_noisynormal_109_1305653972028_F.wav  \n",
            "  inflating: set_b/normal_noisynormal_110_1305655332337_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_110_1305655332337_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_113_1306244002866_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_113_1306244002866_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_115_1306259437619_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_115_1306259437619_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_117_1306262456650_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_117_1306262456650_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_117_1306262456650_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_118_1306262335509_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_118_1306262335509_C1.wav  \n",
            "  inflating: set_b/normal_noisynormal_118_1306262335509_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_121_1306263877235_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_121_1306263877235_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_121_1306263877235_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_123_1306331925797_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_123_1306331925797_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_125_1306332456645_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_125_1306332456645_A2.wav  \n",
            "  inflating: set_b/normal_noisynormal_125_1306332456645_B1.wav  \n",
            "  inflating: set_b/normal_noisynormal_125_1306332456645_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_125_1306332456645_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_127_1306764300147_D1.wav  \n",
            "  inflating: set_b/normal_noisynormal_129_1306344506305_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_129_1306344506305_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_130_1306347376079_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_130_1306347376079_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_132_1306758754432_B1.wav  \n",
            "  inflating: set_b/normal_noisynormal_132_1306758754432_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_133_1306759619127_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_133_1306759619127_B1.wav  \n",
            "  inflating: set_b/normal_noisynormal_133_1306759619127_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_133_1306759619127_D1.wav  \n",
            "  inflating: set_b/normal_noisynormal_134_1306428161797_B1.wav  \n",
            "  inflating: set_b/normal_noisynormal_134_1306428161797_D1.wav  \n",
            "  inflating: set_b/normal_noisynormal_136_1306429977501_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_136_1306429977501_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_136_1306429977501_D1.wav  \n",
            "  inflating: set_b/normal_noisynormal_137_1306764999211_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_137_1306764999211_A2.wav  \n",
            "  inflating: set_b/normal_noisynormal_137_1306764999211_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_137_1306764999211_C1.wav  \n",
            "  inflating: set_b/normal_noisynormal_137_1306764999211_D1.wav  \n",
            "  inflating: set_b/normal_noisynormal_138_1306762146980_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_138_1306762146980_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_139_1306519274653_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_140_1306519735121_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_141_1306520154450_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_141_1306520154450_B1.wav  \n",
            "  inflating: set_b/normal_noisynormal_141_1306520154450_C1.wav  \n",
            "  inflating: set_b/normal_noisynormal_142_1306763049574_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_142_1306763049574_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_142_1306763049574_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_143_1306763822290_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_144_1306522408528_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_144_1306522408528_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_146_1306778707532_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_147_1306523973811_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_149_1306776016110_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_150_1306776340746_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_151_1306779785624_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_154_1306935608852_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_155_1306935902813_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_155_1306935902813_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_157_1306937583792_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_157_1306937583792_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_158_1306947254705_B1.wav  \n",
            "  inflating: set_b/normal_noisynormal_158_1306947254705_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_159_1307018640315_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_159_1307018640315_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_163_1307104470471_D1.wav  \n",
            "  inflating: set_b/normal_noisynormal_167_1307111318050_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_167_1307111318050_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_168_1307970069434_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_169_1307970398039_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_170_1307970562729_C1.wav  \n",
            "  inflating: set_b/normal_noisynormal_172_1307971284351_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_173_1307973611151_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_173_1307973611151_C1.wav  \n",
            "  inflating: set_b/normal_noisynormal_176_1307988171173_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_178_1307989887769_B1.wav  \n",
            "  inflating: set_b/normal_noisynormal_181_1308052613891_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_182_1308053371395_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_188_1308074301731_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_189_1308075231945_A1.wav  \n",
            "  inflating: set_b/normal_noisynormal_194_1308139824187_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_198_1308141739338_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_207_1308159792607_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_216_1308245839516_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_234_1308748855534_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_246_1309199278902_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_258_1309352253234_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_264_1309356143724_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_264_1309356143724_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_264_1309356143724_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_270_1309369533040_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_270_1309369533040_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_271_1309369876160_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_271_1309369876160_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_271_1309369876160_D.wav  \n",
            "  inflating: set_b/normal_noisynormal_278_1311163365896_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_284_1311168471850_A.wav  \n",
            "  inflating: set_b/normal_noisynormal_284_1311168471850_B.wav  \n",
            "  inflating: set_b/normal_noisynormal_285_1311169246969_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_296_1311682952647_C.wav  \n",
            "  inflating: set_b/normal_noisynormal_296_1311682952647_D.wav  \n",
            "   creating: Sound/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOUhX_MzQpgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/'):\n",
        "    for filename in filenames:\n",
        "        pass\n",
        "        #print(os.path.join(dirname, filename))\n",
        "import librosa\n",
        "import librosa.display as libdisplay\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZG8UV7JQ7B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_pad_len = 388\n",
        "\n",
        "def extract_features(file_name):\n",
        "   \n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        pad_width = max_pad_len - mfccs.shape[1]\n",
        "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Algo anda mal: \", file_name)\n",
        "        return None \n",
        "     \n",
        "    return mfccs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtOkzAFgQ_OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = '/content/'\n",
        "metadata = pd.read_csv('/content/set_a.csv')\n",
        "\n",
        "features = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9z9WPMyRjXE",
        "colab_type": "code",
        "outputId": "19ab0ff9-701a-47dd-e7eb-e4d0367b516d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import glob, os\n",
        "os.chdir(\"/content/set_a\")\n",
        "\n",
        "\n",
        "MAX_LEN_MFCC = []\n",
        "\n",
        "for file in glob.glob(\"*.wav\"):\n",
        "    #print(file)\n",
        "    #extract_features(file)\n",
        "\n",
        "    audio,sample_rate = librosa.load(file, res_type='kaiser_fast')\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    #print(mfccs.shape[1])\n",
        "    MAX_LEN_MFCC.append(mfccs.shape[1])\n",
        "\n",
        "print(max(MAX_LEN_MFCC)   )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tMXM3pYR1aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index, row in metadata.iterrows():\n",
        "    file_name = os.path.join(os.path.abspath(dataset_path),str(row['fname']))\n",
        "    \n",
        "    class_label = row['fname']\n",
        "    data = extract_features(file_name)\n",
        "    \n",
        "    features.append([data,class_label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yel6COuwSC0F",
        "colab_type": "code",
        "outputId": "ef815322-3457-404a-e0db-8aa3d86bb02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "DATAX = pd.DataFrame(features, columns=['feature','class_label'])\n",
        "\n",
        "print('Finished feature extraction from ', len(DATAX), ' files')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished feature extraction from  124  files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2uZawTKSWsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(DATAX['class_label'][0]).split('__')[0]\n",
        "\n",
        "LABEL = []\n",
        "\n",
        "for i in range(len(DATAX)):\n",
        "  str(DATAX['class_label'][i]).split('__')[0]\n",
        "  LABEL.append(str(DATAX['class_label'][i]).split('__')[0])    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wgIBFGSSZYJ",
        "colab_type": "code",
        "outputId": "8fd087e6-542d-4852-c1f0-e29e9fa01000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "DATAX['LABEL'] = LABEL\n",
        "NEW_DATAX = DATAX.drop(columns=['class_label'])\n",
        "#NEW_DATAX.to_csv(r'NEW_DATAX.csv')\n",
        "NEW_DATAX.head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-629.3815027521428, -614.3528398171517, -616...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-990.9772750518831, -990.1641333446495, -989...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-632.0832226192613, -622.4774297438613, -623...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-322.1109746901032, -295.3795520831543, -277...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-294.6576987096496, -292.31416581691946, -28...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[[-903.8972458542058, -903.8972458542058, -903...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[[-472.095677624068, -461.82470537247826, -476...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[[-355.33063187666244, -337.0625843885191, -32...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[[-528.5260130536474, -522.9939373044792, -521...</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[[-69.77288599233084, -72.96802317865328, -79....</td>\n",
              "      <td>set_a/artifact</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature           LABEL\n",
              "0  [[-629.3815027521428, -614.3528398171517, -616...  set_a/artifact\n",
              "1  [[-990.9772750518831, -990.1641333446495, -989...  set_a/artifact\n",
              "2  [[-632.0832226192613, -622.4774297438613, -623...  set_a/artifact\n",
              "3  [[-322.1109746901032, -295.3795520831543, -277...  set_a/artifact\n",
              "4  [[-294.6576987096496, -292.31416581691946, -28...  set_a/artifact\n",
              "5  [[-903.8972458542058, -903.8972458542058, -903...  set_a/artifact\n",
              "6  [[-472.095677624068, -461.82470537247826, -476...  set_a/artifact\n",
              "7  [[-355.33063187666244, -337.0625843885191, -32...  set_a/artifact\n",
              "8  [[-528.5260130536474, -522.9939373044792, -521...  set_a/artifact\n",
              "9  [[-69.77288599233084, -72.96802317865328, -79....  set_a/artifact"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPYTUhAlYeDD",
        "colab_type": "code",
        "outputId": "b3cb9c01-a277-46ee-fe06-ef887fc6490d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers, utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = np.array(NEW_DATAX.feature.tolist())\n",
        "y = np.array(NEW_DATAX.LABEL.tolist())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46-LxfLWYgZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "yy = tf.keras.utils.to_categorical(le.fit_transform(y))\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqwLEje5Yi_5",
        "colab_type": "code",
        "outputId": "6fb92dac-b03b-4e23-d866-0af83ed036e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "print('NEW_DATAX shape >> {}'.format(NEW_DATAX.shape))\n",
        "print('len X_train >> {}'.format(len(x_train)))\n",
        "print('len X_test >> {}'.format(len(x_test)))\n",
        "\n",
        "print('X_train shape >> {}'.format(x_train.shape))\n",
        "\n",
        "print('Num_Rows >> {}'.format(len(mfccs)))\n",
        "print('Num_Columns >> {}'.format(max(MAX_LEN_MFCC)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEW_DATAX shape >> (124, 2)\n",
            "len X_train >> 99\n",
            "len X_test >> 25\n",
            "X_train shape >> (99, 40, 388)\n",
            "Num_Rows >> 40\n",
            "Num_Columns >> 388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg0HIhM5ZQ6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_rows = 40\n",
        "num_columns = 388\n",
        "num_channels = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
        "\n",
        "num_labels = yy.shape[1]\n",
        "filter_size = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBAz2-1EjCJn",
        "colab_type": "code",
        "outputId": "c4502156-f740-4265-ba48-10fc4a72dfd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(num_labels, activation='softmax'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hswzyooRjHWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al6cQ9s3jK96",
        "colab_type": "code",
        "outputId": "f40b38f1-6caf-4eb4-8d88-6591460c15fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "model.summary()\n",
        "\n",
        "# Calculate pre-training accuracy \n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 39, 387, 16)       80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 19, 193, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 19, 193, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 18, 192, 32)       2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 9, 96, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9, 96, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 95, 64)         8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 47, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 47, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 46, 128)        32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 23, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 23, 128)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 43,828\n",
            "Trainable params: 43,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "25/25 [==============================] - 7s 273ms/sample - loss: 6.2492 - acc: 0.2800\n",
            "Pre-training accuracy: 28.0000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plDHSfzBjehg",
        "colab_type": "code",
        "outputId": "d2b5d89a-ebe5-471c-c1ad-ee1925f2a7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#tf.keras.callbacks.ModelCheckpoint\n",
        "\n",
        "from datetime import datetime \n",
        "\n",
        "#num_epochs = 500\n",
        "#num_batch_size = 128\n",
        "\n",
        "#num_epochs = 500\n",
        "#num_batch_size = 256\n",
        "\n",
        "num_epochs = 1000\n",
        "num_batch_size = 256\n",
        "\n",
        "#num_epochs = 1000\n",
        "#num_batch_size = 256\n",
        "\n",
        "#checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='sound_classification_Bagus.hdf5', \n",
        "#                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "#model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 99 samples, validate on 25 samples\n",
            "Epoch 1/1000\n",
            "99/99 [==============================] - 0s 449us/sample - loss: 0.0677 - acc: 0.9798 - val_loss: 2.8797 - val_acc: 0.8000\n",
            "Epoch 2/1000\n",
            "99/99 [==============================] - 0s 427us/sample - loss: 0.0840 - acc: 0.9697 - val_loss: 2.9276 - val_acc: 0.7600\n",
            "Epoch 3/1000\n",
            "99/99 [==============================] - 0s 427us/sample - loss: 0.0579 - acc: 0.9596 - val_loss: 2.9501 - val_acc: 0.7600\n",
            "Epoch 4/1000\n",
            "99/99 [==============================] - 0s 424us/sample - loss: 0.0386 - acc: 0.9899 - val_loss: 2.9490 - val_acc: 0.7600\n",
            "Epoch 5/1000\n",
            "99/99 [==============================] - 0s 429us/sample - loss: 0.0644 - acc: 0.9596 - val_loss: 2.8483 - val_acc: 0.7600\n",
            "Epoch 6/1000\n",
            "99/99 [==============================] - 0s 360us/sample - loss: 0.0559 - acc: 0.9697 - val_loss: 2.7408 - val_acc: 0.8000\n",
            "Epoch 7/1000\n",
            "99/99 [==============================] - 0s 360us/sample - loss: 0.0435 - acc: 0.9798 - val_loss: 2.6709 - val_acc: 0.8000\n",
            "Epoch 8/1000\n",
            "99/99 [==============================] - 0s 354us/sample - loss: 0.0597 - acc: 0.9596 - val_loss: 2.6820 - val_acc: 0.8000\n",
            "Epoch 9/1000\n",
            "99/99 [==============================] - 0s 350us/sample - loss: 0.0681 - acc: 0.9697 - val_loss: 2.7482 - val_acc: 0.8000\n",
            "Epoch 10/1000\n",
            "99/99 [==============================] - 0s 364us/sample - loss: 0.0655 - acc: 0.9596 - val_loss: 2.9234 - val_acc: 0.7600\n",
            "Epoch 11/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0578 - acc: 0.9697 - val_loss: 3.0388 - val_acc: 0.7600\n",
            "Epoch 12/1000\n",
            "99/99 [==============================] - 0s 344us/sample - loss: 0.0923 - acc: 0.9596 - val_loss: 3.0614 - val_acc: 0.7600\n",
            "Epoch 13/1000\n",
            "99/99 [==============================] - 0s 349us/sample - loss: 0.0509 - acc: 0.9697 - val_loss: 2.9937 - val_acc: 0.7600\n",
            "Epoch 14/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0493 - acc: 0.9697 - val_loss: 2.9477 - val_acc: 0.7600\n",
            "Epoch 15/1000\n",
            "99/99 [==============================] - 0s 356us/sample - loss: 0.0766 - acc: 0.9596 - val_loss: 2.9478 - val_acc: 0.7600\n",
            "Epoch 16/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0753 - acc: 0.9697 - val_loss: 2.9688 - val_acc: 0.7600\n",
            "Epoch 17/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0352 - acc: 0.9899 - val_loss: 3.0010 - val_acc: 0.7600\n",
            "Epoch 18/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0650 - acc: 0.9899 - val_loss: 2.9845 - val_acc: 0.7600\n",
            "Epoch 19/1000\n",
            "99/99 [==============================] - 0s 307us/sample - loss: 0.0533 - acc: 0.9697 - val_loss: 2.8977 - val_acc: 0.7600\n",
            "Epoch 20/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0422 - acc: 0.9798 - val_loss: 2.8190 - val_acc: 0.8000\n",
            "Epoch 21/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0475 - acc: 0.9798 - val_loss: 2.7188 - val_acc: 0.8000\n",
            "Epoch 22/1000\n",
            "99/99 [==============================] - 0s 307us/sample - loss: 0.0415 - acc: 0.9798 - val_loss: 2.6357 - val_acc: 0.8400\n",
            "Epoch 23/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0631 - acc: 0.9697 - val_loss: 2.6313 - val_acc: 0.8000\n",
            "Epoch 24/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0603 - acc: 0.9596 - val_loss: 2.7407 - val_acc: 0.7600\n",
            "Epoch 25/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0736 - acc: 0.9596 - val_loss: 2.8675 - val_acc: 0.7600\n",
            "Epoch 26/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0496 - acc: 0.9798 - val_loss: 2.9447 - val_acc: 0.7600\n",
            "Epoch 27/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0507 - acc: 0.9798 - val_loss: 2.9578 - val_acc: 0.7600\n",
            "Epoch 28/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0902 - acc: 0.9596 - val_loss: 2.8839 - val_acc: 0.8000\n",
            "Epoch 29/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0596 - acc: 0.9697 - val_loss: 2.7590 - val_acc: 0.8000\n",
            "Epoch 30/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0401 - acc: 0.9899 - val_loss: 2.6793 - val_acc: 0.8400\n",
            "Epoch 31/1000\n",
            "99/99 [==============================] - 0s 345us/sample - loss: 0.0524 - acc: 0.9798 - val_loss: 2.6864 - val_acc: 0.8000\n",
            "Epoch 32/1000\n",
            "99/99 [==============================] - 0s 339us/sample - loss: 0.0692 - acc: 0.9798 - val_loss: 2.7609 - val_acc: 0.8000\n",
            "Epoch 33/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0495 - acc: 0.9798 - val_loss: 2.9062 - val_acc: 0.7600\n",
            "Epoch 34/1000\n",
            "99/99 [==============================] - 0s 341us/sample - loss: 0.0502 - acc: 0.9798 - val_loss: 3.0489 - val_acc: 0.7600\n",
            "Epoch 35/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0491 - acc: 0.9798 - val_loss: 3.1037 - val_acc: 0.7600\n",
            "Epoch 36/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0795 - acc: 0.9697 - val_loss: 3.0412 - val_acc: 0.7600\n",
            "Epoch 37/1000\n",
            "99/99 [==============================] - 0s 339us/sample - loss: 0.1066 - acc: 0.9394 - val_loss: 2.8692 - val_acc: 0.8000\n",
            "Epoch 38/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0446 - acc: 0.9798 - val_loss: 2.6950 - val_acc: 0.8400\n",
            "Epoch 39/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0857 - acc: 0.9596 - val_loss: 2.6457 - val_acc: 0.8000\n",
            "Epoch 40/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0670 - acc: 0.9899 - val_loss: 2.6581 - val_acc: 0.8000\n",
            "Epoch 41/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0962 - acc: 0.9697 - val_loss: 2.7383 - val_acc: 0.8400\n",
            "Epoch 42/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0422 - acc: 0.9798 - val_loss: 2.8097 - val_acc: 0.8400\n",
            "Epoch 43/1000\n",
            "99/99 [==============================] - 0s 354us/sample - loss: 0.0492 - acc: 0.9899 - val_loss: 2.8485 - val_acc: 0.7600\n",
            "Epoch 44/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0345 - acc: 0.9798 - val_loss: 2.8735 - val_acc: 0.7600\n",
            "Epoch 45/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0508 - acc: 0.9798 - val_loss: 2.8691 - val_acc: 0.7600\n",
            "Epoch 46/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0708 - acc: 0.9495 - val_loss: 2.7874 - val_acc: 0.7600\n",
            "Epoch 47/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0441 - acc: 0.9697 - val_loss: 2.7466 - val_acc: 0.8000\n",
            "Epoch 48/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0531 - acc: 0.9899 - val_loss: 2.7696 - val_acc: 0.8000\n",
            "Epoch 49/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0432 - acc: 0.9697 - val_loss: 2.8147 - val_acc: 0.7600\n",
            "Epoch 50/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0490 - acc: 0.9899 - val_loss: 2.8767 - val_acc: 0.7600\n",
            "Epoch 51/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0600 - acc: 0.9697 - val_loss: 2.9329 - val_acc: 0.7600\n",
            "Epoch 52/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0460 - acc: 0.9697 - val_loss: 2.9587 - val_acc: 0.8000\n",
            "Epoch 53/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0481 - acc: 0.9798 - val_loss: 2.9695 - val_acc: 0.7600\n",
            "Epoch 54/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0416 - acc: 0.9798 - val_loss: 2.9592 - val_acc: 0.8000\n",
            "Epoch 55/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0601 - acc: 0.9697 - val_loss: 2.9196 - val_acc: 0.8000\n",
            "Epoch 56/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 2.9019 - val_acc: 0.8000\n",
            "Epoch 57/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 2.8941 - val_acc: 0.8000\n",
            "Epoch 58/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0410 - acc: 0.9899 - val_loss: 2.8936 - val_acc: 0.8000\n",
            "Epoch 59/1000\n",
            "99/99 [==============================] - 0s 355us/sample - loss: 0.0756 - acc: 0.9798 - val_loss: 2.9267 - val_acc: 0.8000\n",
            "Epoch 60/1000\n",
            "99/99 [==============================] - 0s 308us/sample - loss: 0.0400 - acc: 0.9697 - val_loss: 2.9862 - val_acc: 0.8000\n",
            "Epoch 61/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0275 - acc: 0.9899 - val_loss: 3.0522 - val_acc: 0.7600\n",
            "Epoch 62/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0411 - acc: 0.9798 - val_loss: 3.0585 - val_acc: 0.7600\n",
            "Epoch 63/1000\n",
            "99/99 [==============================] - 0s 376us/sample - loss: 0.0841 - acc: 0.9798 - val_loss: 2.9947 - val_acc: 0.7200\n",
            "Epoch 64/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0559 - acc: 0.9596 - val_loss: 2.9461 - val_acc: 0.7200\n",
            "Epoch 65/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0365 - acc: 0.9798 - val_loss: 2.8805 - val_acc: 0.8000\n",
            "Epoch 66/1000\n",
            "99/99 [==============================] - 0s 360us/sample - loss: 0.0703 - acc: 0.9697 - val_loss: 2.8395 - val_acc: 0.8000\n",
            "Epoch 67/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0661 - acc: 0.9697 - val_loss: 2.9144 - val_acc: 0.8000\n",
            "Epoch 68/1000\n",
            "99/99 [==============================] - 0s 342us/sample - loss: 0.0477 - acc: 0.9697 - val_loss: 3.0052 - val_acc: 0.8000\n",
            "Epoch 69/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0374 - acc: 0.9798 - val_loss: 3.1000 - val_acc: 0.8000\n",
            "Epoch 70/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0426 - acc: 0.9798 - val_loss: 3.1527 - val_acc: 0.8000\n",
            "Epoch 71/1000\n",
            "99/99 [==============================] - 0s 360us/sample - loss: 0.0290 - acc: 0.9899 - val_loss: 3.1842 - val_acc: 0.8000\n",
            "Epoch 72/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0506 - acc: 0.9798 - val_loss: 3.1798 - val_acc: 0.8000\n",
            "Epoch 73/1000\n",
            "99/99 [==============================] - 0s 355us/sample - loss: 0.0471 - acc: 0.9899 - val_loss: 3.1491 - val_acc: 0.8000\n",
            "Epoch 74/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0553 - acc: 0.9697 - val_loss: 3.1107 - val_acc: 0.8000\n",
            "Epoch 75/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0384 - acc: 0.9899 - val_loss: 3.0572 - val_acc: 0.8000\n",
            "Epoch 76/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 2.9940 - val_acc: 0.8000\n",
            "Epoch 77/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0303 - acc: 0.9798 - val_loss: 2.9369 - val_acc: 0.8000\n",
            "Epoch 78/1000\n",
            "99/99 [==============================] - 0s 357us/sample - loss: 0.0584 - acc: 0.9798 - val_loss: 2.9151 - val_acc: 0.8000\n",
            "Epoch 79/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0497 - acc: 0.9899 - val_loss: 2.9344 - val_acc: 0.8000\n",
            "Epoch 80/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 2.9761 - val_acc: 0.8000\n",
            "Epoch 81/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0309 - acc: 0.9899 - val_loss: 3.0311 - val_acc: 0.8000\n",
            "Epoch 82/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0311 - acc: 0.9899 - val_loss: 3.0720 - val_acc: 0.7600\n",
            "Epoch 83/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0335 - acc: 0.9899 - val_loss: 3.1107 - val_acc: 0.7600\n",
            "Epoch 84/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0599 - acc: 0.9798 - val_loss: 3.0414 - val_acc: 0.7600\n",
            "Epoch 85/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0478 - acc: 0.9798 - val_loss: 3.0504 - val_acc: 0.7600\n",
            "Epoch 86/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0387 - acc: 0.9798 - val_loss: 3.0838 - val_acc: 0.7600\n",
            "Epoch 87/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0332 - acc: 0.9899 - val_loss: 3.1368 - val_acc: 0.7600\n",
            "Epoch 88/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0534 - acc: 0.9596 - val_loss: 3.1522 - val_acc: 0.7600\n",
            "Epoch 89/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0433 - acc: 0.9798 - val_loss: 3.1638 - val_acc: 0.7600\n",
            "Epoch 90/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0509 - acc: 0.9697 - val_loss: 3.1723 - val_acc: 0.7600\n",
            "Epoch 91/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0340 - acc: 0.9899 - val_loss: 3.1793 - val_acc: 0.8000\n",
            "Epoch 92/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0373 - acc: 0.9899 - val_loss: 3.2144 - val_acc: 0.8000\n",
            "Epoch 93/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0562 - acc: 0.9899 - val_loss: 3.2574 - val_acc: 0.8000\n",
            "Epoch 94/1000\n",
            "99/99 [==============================] - 0s 340us/sample - loss: 0.0381 - acc: 0.9899 - val_loss: 3.2778 - val_acc: 0.7600\n",
            "Epoch 95/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0289 - acc: 0.9899 - val_loss: 3.2663 - val_acc: 0.7600\n",
            "Epoch 96/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0724 - acc: 0.9697 - val_loss: 3.1964 - val_acc: 0.7600\n",
            "Epoch 97/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0326 - acc: 0.9798 - val_loss: 3.1363 - val_acc: 0.8000\n",
            "Epoch 98/1000\n",
            "99/99 [==============================] - 0s 340us/sample - loss: 0.0809 - acc: 0.9596 - val_loss: 3.1169 - val_acc: 0.8000\n",
            "Epoch 99/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0719 - acc: 0.9596 - val_loss: 3.1715 - val_acc: 0.7600\n",
            "Epoch 100/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0324 - acc: 0.9899 - val_loss: 3.2273 - val_acc: 0.7600\n",
            "Epoch 101/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0597 - acc: 0.9798 - val_loss: 3.2497 - val_acc: 0.7600\n",
            "Epoch 102/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0460 - acc: 0.9697 - val_loss: 3.2185 - val_acc: 0.7600\n",
            "Epoch 103/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0455 - acc: 0.9798 - val_loss: 3.1648 - val_acc: 0.8000\n",
            "Epoch 104/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0388 - acc: 0.9798 - val_loss: 3.0479 - val_acc: 0.8000\n",
            "Epoch 105/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0489 - acc: 0.9798 - val_loss: 2.9765 - val_acc: 0.8000\n",
            "Epoch 106/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0430 - acc: 0.9798 - val_loss: 2.9252 - val_acc: 0.8000\n",
            "Epoch 107/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0441 - acc: 0.9798 - val_loss: 2.9002 - val_acc: 0.8000\n",
            "Epoch 108/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0412 - acc: 0.9899 - val_loss: 2.9036 - val_acc: 0.7200\n",
            "Epoch 109/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0617 - acc: 0.9798 - val_loss: 2.9984 - val_acc: 0.7200\n",
            "Epoch 110/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0408 - acc: 0.9697 - val_loss: 3.1062 - val_acc: 0.7600\n",
            "Epoch 111/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0553 - acc: 0.9697 - val_loss: 3.1998 - val_acc: 0.7600\n",
            "Epoch 112/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.1128 - acc: 0.9697 - val_loss: 3.1712 - val_acc: 0.7600\n",
            "Epoch 113/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0509 - acc: 0.9697 - val_loss: 3.0969 - val_acc: 0.7600\n",
            "Epoch 114/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0423 - acc: 0.9798 - val_loss: 2.9974 - val_acc: 0.8000\n",
            "Epoch 115/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0350 - acc: 0.9798 - val_loss: 2.8941 - val_acc: 0.8000\n",
            "Epoch 116/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0499 - acc: 0.9798 - val_loss: 2.8338 - val_acc: 0.8000\n",
            "Epoch 117/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0428 - acc: 0.9697 - val_loss: 2.8296 - val_acc: 0.8000\n",
            "Epoch 118/1000\n",
            "99/99 [==============================] - 0s 348us/sample - loss: 0.0533 - acc: 0.9798 - val_loss: 2.8694 - val_acc: 0.8000\n",
            "Epoch 119/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0539 - acc: 0.9596 - val_loss: 2.9282 - val_acc: 0.8000\n",
            "Epoch 120/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0587 - acc: 0.9697 - val_loss: 3.0600 - val_acc: 0.7600\n",
            "Epoch 121/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0502 - acc: 0.9798 - val_loss: 3.1599 - val_acc: 0.7600\n",
            "Epoch 122/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0283 - acc: 0.9798 - val_loss: 3.2163 - val_acc: 0.7600\n",
            "Epoch 123/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0395 - acc: 0.9798 - val_loss: 3.2123 - val_acc: 0.7600\n",
            "Epoch 124/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0928 - acc: 0.9495 - val_loss: 3.1014 - val_acc: 0.7600\n",
            "Epoch 125/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0594 - acc: 0.9596 - val_loss: 2.9683 - val_acc: 0.8000\n",
            "Epoch 126/1000\n",
            "99/99 [==============================] - 0s 364us/sample - loss: 0.0341 - acc: 0.9798 - val_loss: 2.8801 - val_acc: 0.8000\n",
            "Epoch 127/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0563 - acc: 0.9596 - val_loss: 2.8338 - val_acc: 0.8000\n",
            "Epoch 128/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0546 - acc: 0.9798 - val_loss: 2.8337 - val_acc: 0.8000\n",
            "Epoch 129/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0836 - acc: 0.9798 - val_loss: 2.8874 - val_acc: 0.7600\n",
            "Epoch 130/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0349 - acc: 0.9798 - val_loss: 2.9600 - val_acc: 0.7600\n",
            "Epoch 131/1000\n",
            "99/99 [==============================] - 0s 306us/sample - loss: 0.0374 - acc: 0.9899 - val_loss: 3.0818 - val_acc: 0.7600\n",
            "Epoch 132/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0424 - acc: 0.9697 - val_loss: 3.1375 - val_acc: 0.7600\n",
            "Epoch 133/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0434 - acc: 0.9798 - val_loss: 3.1075 - val_acc: 0.7600\n",
            "Epoch 134/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0410 - acc: 0.9798 - val_loss: 3.0462 - val_acc: 0.8000\n",
            "Epoch 135/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0346 - acc: 0.9798 - val_loss: 2.9713 - val_acc: 0.8000\n",
            "Epoch 136/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0409 - acc: 0.9697 - val_loss: 2.9155 - val_acc: 0.8000\n",
            "Epoch 137/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0262 - acc: 0.9899 - val_loss: 2.8653 - val_acc: 0.8000\n",
            "Epoch 138/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0641 - acc: 0.9798 - val_loss: 2.8802 - val_acc: 0.8000\n",
            "Epoch 139/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0628 - acc: 0.9596 - val_loss: 2.9373 - val_acc: 0.8000\n",
            "Epoch 140/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0368 - acc: 0.9798 - val_loss: 3.0099 - val_acc: 0.7600\n",
            "Epoch 141/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 3.0939 - val_acc: 0.7600\n",
            "Epoch 142/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0242 - acc: 0.9899 - val_loss: 3.1684 - val_acc: 0.7600\n",
            "Epoch 143/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0415 - acc: 0.9798 - val_loss: 3.1767 - val_acc: 0.8000\n",
            "Epoch 144/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0759 - acc: 0.9495 - val_loss: 3.0425 - val_acc: 0.8000\n",
            "Epoch 145/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 2.9198 - val_acc: 0.8000\n",
            "Epoch 146/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0487 - acc: 0.9798 - val_loss: 2.8393 - val_acc: 0.8400\n",
            "Epoch 147/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0319 - acc: 0.9899 - val_loss: 2.7956 - val_acc: 0.8400\n",
            "Epoch 148/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0654 - acc: 0.9798 - val_loss: 2.7965 - val_acc: 0.8400\n",
            "Epoch 149/1000\n",
            "99/99 [==============================] - 0s 347us/sample - loss: 0.0327 - acc: 0.9899 - val_loss: 2.8270 - val_acc: 0.8400\n",
            "Epoch 150/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0453 - acc: 0.9798 - val_loss: 2.9143 - val_acc: 0.8400\n",
            "Epoch 151/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0683 - acc: 0.9596 - val_loss: 3.1462 - val_acc: 0.8000\n",
            "Epoch 152/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0398 - acc: 0.9899 - val_loss: 3.3549 - val_acc: 0.7600\n",
            "Epoch 153/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0899 - acc: 0.9495 - val_loss: 3.2683 - val_acc: 0.7600\n",
            "Epoch 154/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0597 - acc: 0.9697 - val_loss: 3.0692 - val_acc: 0.7600\n",
            "Epoch 155/1000\n",
            "99/99 [==============================] - 0s 363us/sample - loss: 0.0629 - acc: 0.9798 - val_loss: 2.8935 - val_acc: 0.8000\n",
            "Epoch 156/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0482 - acc: 0.9697 - val_loss: 2.7815 - val_acc: 0.8000\n",
            "Epoch 157/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0532 - acc: 0.9697 - val_loss: 2.7443 - val_acc: 0.8000\n",
            "Epoch 158/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.1006 - acc: 0.9596 - val_loss: 2.9002 - val_acc: 0.7600\n",
            "Epoch 159/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0258 - acc: 0.9899 - val_loss: 3.0513 - val_acc: 0.7600\n",
            "Epoch 160/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0313 - acc: 0.9899 - val_loss: 3.1442 - val_acc: 0.7600\n",
            "Epoch 161/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0464 - acc: 0.9798 - val_loss: 3.0850 - val_acc: 0.7600\n",
            "Epoch 162/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0652 - acc: 0.9495 - val_loss: 2.9666 - val_acc: 0.8000\n",
            "Epoch 163/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0598 - acc: 0.9697 - val_loss: 2.8418 - val_acc: 0.8000\n",
            "Epoch 164/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0749 - acc: 0.9596 - val_loss: 2.7104 - val_acc: 0.8000\n",
            "Epoch 165/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0379 - acc: 0.9899 - val_loss: 2.6443 - val_acc: 0.8000\n",
            "Epoch 166/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.1098 - acc: 0.9495 - val_loss: 2.7462 - val_acc: 0.8000\n",
            "Epoch 167/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0464 - acc: 0.9697 - val_loss: 2.9609 - val_acc: 0.7600\n",
            "Epoch 168/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0265 - acc: 0.9798 - val_loss: 3.1647 - val_acc: 0.7600\n",
            "Epoch 169/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0539 - acc: 0.9697 - val_loss: 3.3232 - val_acc: 0.7600\n",
            "Epoch 170/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0469 - acc: 0.9798 - val_loss: 3.3761 - val_acc: 0.7600\n",
            "Epoch 171/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0266 - acc: 0.9899 - val_loss: 3.3666 - val_acc: 0.7600\n",
            "Epoch 172/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0405 - acc: 0.9697 - val_loss: 3.2567 - val_acc: 0.7200\n",
            "Epoch 173/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0656 - acc: 0.9697 - val_loss: 3.1566 - val_acc: 0.7600\n",
            "Epoch 174/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0558 - acc: 0.9899 - val_loss: 3.0995 - val_acc: 0.7600\n",
            "Epoch 175/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0799 - acc: 0.9495 - val_loss: 3.1130 - val_acc: 0.8000\n",
            "Epoch 176/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0472 - acc: 0.9798 - val_loss: 3.1540 - val_acc: 0.8000\n",
            "Epoch 177/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0381 - acc: 0.9899 - val_loss: 3.2182 - val_acc: 0.8000\n",
            "Epoch 178/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0496 - acc: 0.9798 - val_loss: 3.2684 - val_acc: 0.8000\n",
            "Epoch 179/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0497 - acc: 0.9697 - val_loss: 3.2798 - val_acc: 0.7600\n",
            "Epoch 180/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0441 - acc: 0.9697 - val_loss: 3.2042 - val_acc: 0.7600\n",
            "Epoch 181/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0316 - acc: 0.9899 - val_loss: 3.1024 - val_acc: 0.7600\n",
            "Epoch 182/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0429 - acc: 0.9798 - val_loss: 2.9616 - val_acc: 0.7200\n",
            "Epoch 183/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0502 - acc: 0.9697 - val_loss: 2.8252 - val_acc: 0.7200\n",
            "Epoch 184/1000\n",
            "99/99 [==============================] - 0s 345us/sample - loss: 0.0459 - acc: 0.9798 - val_loss: 2.7537 - val_acc: 0.7200\n",
            "Epoch 185/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.1052 - acc: 0.9798 - val_loss: 2.8641 - val_acc: 0.7600\n",
            "Epoch 186/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0357 - acc: 0.9899 - val_loss: 3.0031 - val_acc: 0.7600\n",
            "Epoch 187/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0281 - acc: 0.9899 - val_loss: 3.1356 - val_acc: 0.7600\n",
            "Epoch 188/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0262 - acc: 0.9899 - val_loss: 3.2187 - val_acc: 0.7600\n",
            "Epoch 189/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0517 - acc: 0.9697 - val_loss: 3.2416 - val_acc: 0.8000\n",
            "Epoch 190/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0664 - acc: 0.9697 - val_loss: 3.1084 - val_acc: 0.8000\n",
            "Epoch 191/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0494 - acc: 0.9798 - val_loss: 2.9726 - val_acc: 0.8000\n",
            "Epoch 192/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 2.8692 - val_acc: 0.8000\n",
            "Epoch 193/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0572 - acc: 0.9697 - val_loss: 2.8114 - val_acc: 0.8000\n",
            "Epoch 194/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0469 - acc: 0.9697 - val_loss: 2.7756 - val_acc: 0.8000\n",
            "Epoch 195/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0646 - acc: 0.9798 - val_loss: 2.7961 - val_acc: 0.8000\n",
            "Epoch 196/1000\n",
            "99/99 [==============================] - 0s 304us/sample - loss: 0.0411 - acc: 0.9798 - val_loss: 2.8258 - val_acc: 0.8000\n",
            "Epoch 197/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0329 - acc: 0.9899 - val_loss: 2.8740 - val_acc: 0.8000\n",
            "Epoch 198/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0417 - acc: 0.9899 - val_loss: 2.9546 - val_acc: 0.7600\n",
            "Epoch 199/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0353 - acc: 0.9798 - val_loss: 3.0627 - val_acc: 0.7600\n",
            "Epoch 200/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0668 - acc: 0.9596 - val_loss: 3.0868 - val_acc: 0.7600\n",
            "Epoch 201/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0319 - acc: 0.9899 - val_loss: 3.0702 - val_acc: 0.7600\n",
            "Epoch 202/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0735 - acc: 0.9596 - val_loss: 2.9905 - val_acc: 0.7600\n",
            "Epoch 203/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0657 - acc: 0.9798 - val_loss: 2.8839 - val_acc: 0.8000\n",
            "Epoch 204/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0487 - acc: 0.9697 - val_loss: 2.7980 - val_acc: 0.8000\n",
            "Epoch 205/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0451 - acc: 0.9798 - val_loss: 2.7503 - val_acc: 0.8000\n",
            "Epoch 206/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0617 - acc: 0.9697 - val_loss: 2.7486 - val_acc: 0.8000\n",
            "Epoch 207/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0772 - acc: 0.9596 - val_loss: 2.8424 - val_acc: 0.8000\n",
            "Epoch 208/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0466 - acc: 0.9899 - val_loss: 3.0410 - val_acc: 0.8000\n",
            "Epoch 209/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0459 - acc: 0.9798 - val_loss: 3.2144 - val_acc: 0.8000\n",
            "Epoch 210/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0315 - acc: 0.9899 - val_loss: 3.2613 - val_acc: 0.7600\n",
            "Epoch 211/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 3.2759 - val_acc: 0.7200\n",
            "Epoch 212/1000\n",
            "99/99 [==============================] - 0s 344us/sample - loss: 0.0553 - acc: 0.9596 - val_loss: 3.2534 - val_acc: 0.7200\n",
            "Epoch 213/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0344 - acc: 0.9899 - val_loss: 3.1764 - val_acc: 0.7200\n",
            "Epoch 214/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0245 - acc: 0.9899 - val_loss: 3.1001 - val_acc: 0.7600\n",
            "Epoch 215/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0762 - acc: 0.9596 - val_loss: 3.0613 - val_acc: 0.7600\n",
            "Epoch 216/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0417 - acc: 0.9798 - val_loss: 3.0439 - val_acc: 0.7600\n",
            "Epoch 217/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 3.0165 - val_acc: 0.7600\n",
            "Epoch 218/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0535 - acc: 0.9697 - val_loss: 2.9964 - val_acc: 0.7600\n",
            "Epoch 219/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 2.9834 - val_acc: 0.7600\n",
            "Epoch 220/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0394 - acc: 0.9697 - val_loss: 2.9289 - val_acc: 0.8000\n",
            "Epoch 221/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0252 - acc: 0.9899 - val_loss: 2.8882 - val_acc: 0.8000\n",
            "Epoch 222/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0338 - acc: 0.9798 - val_loss: 2.8561 - val_acc: 0.8000\n",
            "Epoch 223/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0443 - acc: 0.9697 - val_loss: 2.8812 - val_acc: 0.8000\n",
            "Epoch 224/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0412 - acc: 0.9899 - val_loss: 2.8982 - val_acc: 0.8000\n",
            "Epoch 225/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0320 - acc: 0.9798 - val_loss: 2.9099 - val_acc: 0.8000\n",
            "Epoch 226/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0503 - acc: 0.9798 - val_loss: 2.8976 - val_acc: 0.8000\n",
            "Epoch 227/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0339 - acc: 0.9798 - val_loss: 2.9127 - val_acc: 0.8000\n",
            "Epoch 228/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0482 - acc: 0.9798 - val_loss: 2.9718 - val_acc: 0.8000\n",
            "Epoch 229/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0339 - acc: 0.9798 - val_loss: 3.0165 - val_acc: 0.7600\n",
            "Epoch 230/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0358 - acc: 0.9798 - val_loss: 3.0185 - val_acc: 0.7600\n",
            "Epoch 231/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0362 - acc: 0.9798 - val_loss: 2.9904 - val_acc: 0.7600\n",
            "Epoch 232/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0401 - acc: 0.9798 - val_loss: 2.9631 - val_acc: 0.7600\n",
            "Epoch 233/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0539 - acc: 0.9697 - val_loss: 3.0258 - val_acc: 0.7600\n",
            "Epoch 234/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0529 - acc: 0.9697 - val_loss: 3.1432 - val_acc: 0.7600\n",
            "Epoch 235/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0175 - acc: 0.9899 - val_loss: 3.2455 - val_acc: 0.7600\n",
            "Epoch 236/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0677 - acc: 0.9697 - val_loss: 3.2294 - val_acc: 0.7600\n",
            "Epoch 237/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0743 - acc: 0.9596 - val_loss: 3.1181 - val_acc: 0.7600\n",
            "Epoch 238/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0394 - acc: 0.9697 - val_loss: 3.0363 - val_acc: 0.8000\n",
            "Epoch 239/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0617 - acc: 0.9798 - val_loss: 2.9926 - val_acc: 0.8000\n",
            "Epoch 240/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0724 - acc: 0.9697 - val_loss: 2.9471 - val_acc: 0.8000\n",
            "Epoch 241/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0812 - acc: 0.9596 - val_loss: 2.9480 - val_acc: 0.8000\n",
            "Epoch 242/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0314 - acc: 0.9899 - val_loss: 2.9836 - val_acc: 0.8000\n",
            "Epoch 243/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0453 - acc: 0.9899 - val_loss: 2.9669 - val_acc: 0.8000\n",
            "Epoch 244/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0796 - acc: 0.9596 - val_loss: 2.9311 - val_acc: 0.8000\n",
            "Epoch 245/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0817 - acc: 0.9495 - val_loss: 2.8143 - val_acc: 0.8000\n",
            "Epoch 246/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0332 - acc: 0.9899 - val_loss: 2.7365 - val_acc: 0.8400\n",
            "Epoch 247/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0285 - acc: 0.9798 - val_loss: 2.7351 - val_acc: 0.8000\n",
            "Epoch 248/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0621 - acc: 0.9697 - val_loss: 2.8170 - val_acc: 0.7200\n",
            "Epoch 249/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0759 - acc: 0.9596 - val_loss: 2.8598 - val_acc: 0.7200\n",
            "Epoch 250/1000\n",
            "99/99 [==============================] - 0s 308us/sample - loss: 0.0764 - acc: 0.9596 - val_loss: 2.8153 - val_acc: 0.8000\n",
            "Epoch 251/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 2.8155 - val_acc: 0.8400\n",
            "Epoch 252/1000\n",
            "99/99 [==============================] - 0s 305us/sample - loss: 0.0330 - acc: 0.9899 - val_loss: 2.8368 - val_acc: 0.8400\n",
            "Epoch 253/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0991 - acc: 0.9596 - val_loss: 2.8998 - val_acc: 0.8400\n",
            "Epoch 254/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0420 - acc: 0.9899 - val_loss: 2.9578 - val_acc: 0.8400\n",
            "Epoch 255/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0572 - acc: 0.9697 - val_loss: 3.0185 - val_acc: 0.8400\n",
            "Epoch 256/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0538 - acc: 0.9798 - val_loss: 2.9747 - val_acc: 0.8400\n",
            "Epoch 257/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0543 - acc: 0.9596 - val_loss: 2.8914 - val_acc: 0.8400\n",
            "Epoch 258/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0474 - acc: 0.9798 - val_loss: 2.7975 - val_acc: 0.8000\n",
            "Epoch 259/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0474 - acc: 0.9798 - val_loss: 2.6646 - val_acc: 0.8400\n",
            "Epoch 260/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0394 - acc: 0.9899 - val_loss: 2.5308 - val_acc: 0.8000\n",
            "Epoch 261/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0478 - acc: 0.9798 - val_loss: 2.4516 - val_acc: 0.8000\n",
            "Epoch 262/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0222 - acc: 0.9899 - val_loss: 2.4122 - val_acc: 0.8000\n",
            "Epoch 263/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 2.4620 - val_acc: 0.7600\n",
            "Epoch 264/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0349 - acc: 0.9798 - val_loss: 2.5384 - val_acc: 0.8000\n",
            "Epoch 265/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0235 - acc: 0.9899 - val_loss: 2.6151 - val_acc: 0.8000\n",
            "Epoch 266/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0456 - acc: 0.9899 - val_loss: 2.6287 - val_acc: 0.8000\n",
            "Epoch 267/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0580 - acc: 0.9697 - val_loss: 2.6117 - val_acc: 0.8000\n",
            "Epoch 268/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 2.5517 - val_acc: 0.8000\n",
            "Epoch 269/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0341 - acc: 0.9899 - val_loss: 2.5063 - val_acc: 0.8000\n",
            "Epoch 270/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0831 - acc: 0.9697 - val_loss: 2.5960 - val_acc: 0.8000\n",
            "Epoch 271/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0603 - acc: 0.9697 - val_loss: 2.7170 - val_acc: 0.8000\n",
            "Epoch 272/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0382 - acc: 0.9798 - val_loss: 2.8400 - val_acc: 0.8000\n",
            "Epoch 273/1000\n",
            "99/99 [==============================] - 0s 371us/sample - loss: 0.0429 - acc: 0.9798 - val_loss: 2.9383 - val_acc: 0.7600\n",
            "Epoch 274/1000\n",
            "99/99 [==============================] - 0s 347us/sample - loss: 0.0484 - acc: 0.9798 - val_loss: 2.9430 - val_acc: 0.7200\n",
            "Epoch 275/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0427 - acc: 0.9697 - val_loss: 2.9191 - val_acc: 0.7200\n",
            "Epoch 276/1000\n",
            "99/99 [==============================] - 0s 349us/sample - loss: 0.0637 - acc: 0.9798 - val_loss: 2.8622 - val_acc: 0.7600\n",
            "Epoch 277/1000\n",
            "99/99 [==============================] - 0s 340us/sample - loss: 0.0519 - acc: 0.9798 - val_loss: 2.8097 - val_acc: 0.7600\n",
            "Epoch 278/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0631 - acc: 0.9798 - val_loss: 2.7564 - val_acc: 0.8000\n",
            "Epoch 279/1000\n",
            "99/99 [==============================] - 0s 341us/sample - loss: 0.0451 - acc: 0.9798 - val_loss: 2.7499 - val_acc: 0.8000\n",
            "Epoch 280/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0458 - acc: 0.9596 - val_loss: 2.7889 - val_acc: 0.8000\n",
            "Epoch 281/1000\n",
            "99/99 [==============================] - 0s 345us/sample - loss: 0.0323 - acc: 0.9899 - val_loss: 2.8698 - val_acc: 0.8000\n",
            "Epoch 282/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0376 - acc: 0.9798 - val_loss: 2.9276 - val_acc: 0.8000\n",
            "Epoch 283/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0782 - acc: 0.9697 - val_loss: 2.9091 - val_acc: 0.8000\n",
            "Epoch 284/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0337 - acc: 0.9798 - val_loss: 2.8834 - val_acc: 0.8000\n",
            "Epoch 285/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0400 - acc: 0.9697 - val_loss: 2.8073 - val_acc: 0.8000\n",
            "Epoch 286/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0296 - acc: 0.9899 - val_loss: 2.7472 - val_acc: 0.8000\n",
            "Epoch 287/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0298 - acc: 0.9899 - val_loss: 2.6861 - val_acc: 0.8000\n",
            "Epoch 288/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0421 - acc: 0.9798 - val_loss: 2.6629 - val_acc: 0.8000\n",
            "Epoch 289/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 2.6740 - val_acc: 0.8000\n",
            "Epoch 290/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0358 - acc: 0.9899 - val_loss: 2.7299 - val_acc: 0.7600\n",
            "Epoch 291/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0414 - acc: 0.9899 - val_loss: 2.8166 - val_acc: 0.7200\n",
            "Epoch 292/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0585 - acc: 0.9697 - val_loss: 2.8298 - val_acc: 0.7200\n",
            "Epoch 293/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0471 - acc: 0.9697 - val_loss: 2.7893 - val_acc: 0.7600\n",
            "Epoch 294/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0534 - acc: 0.9697 - val_loss: 2.7714 - val_acc: 0.8000\n",
            "Epoch 295/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0420 - acc: 0.9899 - val_loss: 2.7932 - val_acc: 0.8000\n",
            "Epoch 296/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0526 - acc: 0.9798 - val_loss: 2.8166 - val_acc: 0.8000\n",
            "Epoch 297/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0608 - acc: 0.9798 - val_loss: 2.8168 - val_acc: 0.8000\n",
            "Epoch 298/1000\n",
            "99/99 [==============================] - 0s 369us/sample - loss: 0.0306 - acc: 0.9899 - val_loss: 2.8280 - val_acc: 0.8000\n",
            "Epoch 299/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0352 - acc: 0.9798 - val_loss: 2.8445 - val_acc: 0.8000\n",
            "Epoch 300/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0536 - acc: 0.9697 - val_loss: 2.8466 - val_acc: 0.8000\n",
            "Epoch 301/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0420 - acc: 0.9899 - val_loss: 2.8157 - val_acc: 0.8000\n",
            "Epoch 302/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0444 - acc: 0.9697 - val_loss: 2.7818 - val_acc: 0.8000\n",
            "Epoch 303/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0403 - acc: 0.9697 - val_loss: 2.8167 - val_acc: 0.8000\n",
            "Epoch 304/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 2.9037 - val_acc: 0.8000\n",
            "Epoch 305/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0450 - acc: 0.9798 - val_loss: 2.9803 - val_acc: 0.8000\n",
            "Epoch 306/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0398 - acc: 0.9697 - val_loss: 3.0527 - val_acc: 0.8000\n",
            "Epoch 307/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0449 - acc: 0.9697 - val_loss: 3.1049 - val_acc: 0.8000\n",
            "Epoch 308/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0404 - acc: 0.9798 - val_loss: 3.1478 - val_acc: 0.8000\n",
            "Epoch 309/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0404 - acc: 0.9798 - val_loss: 3.1802 - val_acc: 0.8000\n",
            "Epoch 310/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0326 - acc: 0.9899 - val_loss: 3.1380 - val_acc: 0.8000\n",
            "Epoch 311/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0329 - acc: 0.9798 - val_loss: 3.0683 - val_acc: 0.8000\n",
            "Epoch 312/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0313 - acc: 0.9899 - val_loss: 2.9980 - val_acc: 0.8000\n",
            "Epoch 313/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0277 - acc: 0.9899 - val_loss: 2.9224 - val_acc: 0.8400\n",
            "Epoch 314/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0417 - acc: 0.9798 - val_loss: 2.8960 - val_acc: 0.8400\n",
            "Epoch 315/1000\n",
            "99/99 [==============================] - 0s 342us/sample - loss: 0.0368 - acc: 0.9798 - val_loss: 2.8924 - val_acc: 0.8400\n",
            "Epoch 316/1000\n",
            "99/99 [==============================] - 0s 365us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 2.8939 - val_acc: 0.8000\n",
            "Epoch 317/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 2.8811 - val_acc: 0.8000\n",
            "Epoch 318/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0385 - acc: 0.9899 - val_loss: 2.8943 - val_acc: 0.8000\n",
            "Epoch 319/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0238 - acc: 0.9899 - val_loss: 2.9148 - val_acc: 0.8000\n",
            "Epoch 320/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0614 - acc: 0.9596 - val_loss: 2.9107 - val_acc: 0.8000\n",
            "Epoch 321/1000\n",
            "99/99 [==============================] - 0s 349us/sample - loss: 0.0377 - acc: 0.9899 - val_loss: 2.8987 - val_acc: 0.8000\n",
            "Epoch 322/1000\n",
            "99/99 [==============================] - 0s 343us/sample - loss: 0.0482 - acc: 0.9798 - val_loss: 2.9028 - val_acc: 0.8000\n",
            "Epoch 323/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0233 - acc: 0.9899 - val_loss: 2.9116 - val_acc: 0.8000\n",
            "Epoch 324/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0430 - acc: 0.9798 - val_loss: 2.9564 - val_acc: 0.8000\n",
            "Epoch 325/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0276 - acc: 0.9899 - val_loss: 2.9725 - val_acc: 0.8000\n",
            "Epoch 326/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0287 - acc: 0.9899 - val_loss: 2.9970 - val_acc: 0.8000\n",
            "Epoch 327/1000\n",
            "99/99 [==============================] - 0s 354us/sample - loss: 0.0480 - acc: 0.9899 - val_loss: 2.9873 - val_acc: 0.8000\n",
            "Epoch 328/1000\n",
            "99/99 [==============================] - 0s 361us/sample - loss: 0.0219 - acc: 0.9899 - val_loss: 2.9748 - val_acc: 0.8000\n",
            "Epoch 329/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0281 - acc: 0.9798 - val_loss: 2.9680 - val_acc: 0.8000\n",
            "Epoch 330/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0349 - acc: 0.9798 - val_loss: 2.9415 - val_acc: 0.8000\n",
            "Epoch 331/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0270 - acc: 0.9899 - val_loss: 2.9323 - val_acc: 0.8000\n",
            "Epoch 332/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0292 - acc: 0.9899 - val_loss: 2.9187 - val_acc: 0.8000\n",
            "Epoch 333/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0332 - acc: 0.9899 - val_loss: 2.9235 - val_acc: 0.8000\n",
            "Epoch 334/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0319 - acc: 0.9798 - val_loss: 2.9683 - val_acc: 0.8000\n",
            "Epoch 335/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0367 - acc: 0.9798 - val_loss: 3.0189 - val_acc: 0.8000\n",
            "Epoch 336/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0265 - acc: 0.9798 - val_loss: 3.0668 - val_acc: 0.8000\n",
            "Epoch 337/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0227 - acc: 0.9899 - val_loss: 3.0698 - val_acc: 0.8000\n",
            "Epoch 338/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0278 - acc: 0.9899 - val_loss: 3.0618 - val_acc: 0.8000\n",
            "Epoch 339/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0539 - acc: 0.9697 - val_loss: 3.0837 - val_acc: 0.8000\n",
            "Epoch 340/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0598 - acc: 0.9798 - val_loss: 3.0887 - val_acc: 0.8000\n",
            "Epoch 341/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0549 - acc: 0.9798 - val_loss: 3.0655 - val_acc: 0.7600\n",
            "Epoch 342/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0489 - acc: 0.9697 - val_loss: 3.0433 - val_acc: 0.7600\n",
            "Epoch 343/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 3.0190 - val_acc: 0.7600\n",
            "Epoch 344/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0300 - acc: 0.9798 - val_loss: 2.9843 - val_acc: 0.7600\n",
            "Epoch 345/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0290 - acc: 0.9899 - val_loss: 2.9630 - val_acc: 0.7600\n",
            "Epoch 346/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 2.9255 - val_acc: 0.7600\n",
            "Epoch 347/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0328 - acc: 0.9798 - val_loss: 2.8914 - val_acc: 0.7600\n",
            "Epoch 348/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0266 - acc: 0.9899 - val_loss: 2.8526 - val_acc: 0.7600\n",
            "Epoch 349/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0260 - acc: 0.9899 - val_loss: 2.8182 - val_acc: 0.8000\n",
            "Epoch 350/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0404 - acc: 0.9697 - val_loss: 2.7992 - val_acc: 0.8000\n",
            "Epoch 351/1000\n",
            "99/99 [==============================] - 0s 354us/sample - loss: 0.0240 - acc: 0.9899 - val_loss: 2.7879 - val_acc: 0.8000\n",
            "Epoch 352/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0534 - acc: 0.9798 - val_loss: 2.8412 - val_acc: 0.8000\n",
            "Epoch 353/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0453 - acc: 0.9697 - val_loss: 2.9060 - val_acc: 0.8000\n",
            "Epoch 354/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0323 - acc: 0.9899 - val_loss: 3.0089 - val_acc: 0.7600\n",
            "Epoch 355/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 3.0921 - val_acc: 0.7200\n",
            "Epoch 356/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0317 - acc: 0.9899 - val_loss: 3.0943 - val_acc: 0.7200\n",
            "Epoch 357/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0668 - acc: 0.9596 - val_loss: 2.9739 - val_acc: 0.7200\n",
            "Epoch 358/1000\n",
            "99/99 [==============================] - 0s 308us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 2.8637 - val_acc: 0.8000\n",
            "Epoch 359/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0309 - acc: 0.9899 - val_loss: 2.7883 - val_acc: 0.8400\n",
            "Epoch 360/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0338 - acc: 0.9798 - val_loss: 2.7577 - val_acc: 0.8400\n",
            "Epoch 361/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0472 - acc: 0.9697 - val_loss: 2.7896 - val_acc: 0.8400\n",
            "Epoch 362/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0428 - acc: 0.9697 - val_loss: 2.8670 - val_acc: 0.8000\n",
            "Epoch 363/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 2.9563 - val_acc: 0.7200\n",
            "Epoch 364/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0360 - acc: 0.9697 - val_loss: 3.0108 - val_acc: 0.7200\n",
            "Epoch 365/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0999 - acc: 0.9798 - val_loss: 2.9947 - val_acc: 0.8000\n",
            "Epoch 366/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0295 - acc: 0.9899 - val_loss: 2.9620 - val_acc: 0.8000\n",
            "Epoch 367/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0433 - acc: 0.9798 - val_loss: 2.9189 - val_acc: 0.8000\n",
            "Epoch 368/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0614 - acc: 0.9495 - val_loss: 2.8492 - val_acc: 0.8000\n",
            "Epoch 369/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0254 - acc: 0.9899 - val_loss: 2.7975 - val_acc: 0.8000\n",
            "Epoch 370/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0305 - acc: 0.9899 - val_loss: 2.7470 - val_acc: 0.8400\n",
            "Epoch 371/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0623 - acc: 0.9697 - val_loss: 2.7362 - val_acc: 0.8000\n",
            "Epoch 372/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 2.7526 - val_acc: 0.8000\n",
            "Epoch 373/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0336 - acc: 0.9899 - val_loss: 2.7890 - val_acc: 0.8000\n",
            "Epoch 374/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0584 - acc: 0.9697 - val_loss: 2.8723 - val_acc: 0.8000\n",
            "Epoch 375/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0466 - acc: 0.9798 - val_loss: 2.9235 - val_acc: 0.7600\n",
            "Epoch 376/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0384 - acc: 0.9697 - val_loss: 2.9424 - val_acc: 0.8000\n",
            "Epoch 377/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0606 - acc: 0.9798 - val_loss: 2.8871 - val_acc: 0.8000\n",
            "Epoch 378/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0368 - acc: 0.9899 - val_loss: 2.8243 - val_acc: 0.8000\n",
            "Epoch 379/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0419 - acc: 0.9899 - val_loss: 2.7799 - val_acc: 0.8000\n",
            "Epoch 380/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0314 - acc: 0.9899 - val_loss: 2.7829 - val_acc: 0.8400\n",
            "Epoch 381/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0321 - acc: 0.9899 - val_loss: 2.8311 - val_acc: 0.8400\n",
            "Epoch 382/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0447 - acc: 0.9798 - val_loss: 2.8666 - val_acc: 0.8000\n",
            "Epoch 383/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0522 - acc: 0.9697 - val_loss: 2.8846 - val_acc: 0.8000\n",
            "Epoch 384/1000\n",
            "99/99 [==============================] - 0s 349us/sample - loss: 0.0326 - acc: 0.9899 - val_loss: 2.8753 - val_acc: 0.8000\n",
            "Epoch 385/1000\n",
            "99/99 [==============================] - 0s 348us/sample - loss: 0.0570 - acc: 0.9798 - val_loss: 2.8848 - val_acc: 0.8000\n",
            "Epoch 386/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0239 - acc: 0.9798 - val_loss: 2.9083 - val_acc: 0.8000\n",
            "Epoch 387/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0225 - acc: 0.9899 - val_loss: 2.9301 - val_acc: 0.8000\n",
            "Epoch 388/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0342 - acc: 0.9798 - val_loss: 2.9634 - val_acc: 0.8000\n",
            "Epoch 389/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0240 - acc: 0.9899 - val_loss: 2.9966 - val_acc: 0.8000\n",
            "Epoch 390/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0486 - acc: 0.9697 - val_loss: 2.9778 - val_acc: 0.8000\n",
            "Epoch 391/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 2.9730 - val_acc: 0.8000\n",
            "Epoch 392/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0511 - acc: 0.9697 - val_loss: 2.9552 - val_acc: 0.8000\n",
            "Epoch 393/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0333 - acc: 0.9798 - val_loss: 2.9474 - val_acc: 0.7600\n",
            "Epoch 394/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0479 - acc: 0.9697 - val_loss: 2.9546 - val_acc: 0.7600\n",
            "Epoch 395/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0308 - acc: 0.9798 - val_loss: 2.9743 - val_acc: 0.7200\n",
            "Epoch 396/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0367 - acc: 0.9899 - val_loss: 2.9653 - val_acc: 0.7200\n",
            "Epoch 397/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0589 - acc: 0.9697 - val_loss: 2.8738 - val_acc: 0.7600\n",
            "Epoch 398/1000\n",
            "99/99 [==============================] - 0s 307us/sample - loss: 0.0311 - acc: 0.9899 - val_loss: 2.8166 - val_acc: 0.8000\n",
            "Epoch 399/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0297 - acc: 0.9899 - val_loss: 2.8100 - val_acc: 0.8000\n",
            "Epoch 400/1000\n",
            "99/99 [==============================] - 0s 341us/sample - loss: 0.0650 - acc: 0.9697 - val_loss: 2.8407 - val_acc: 0.8000\n",
            "Epoch 401/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0381 - acc: 0.9899 - val_loss: 2.8567 - val_acc: 0.8000\n",
            "Epoch 402/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0387 - acc: 0.9798 - val_loss: 2.9097 - val_acc: 0.8000\n",
            "Epoch 403/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0639 - acc: 0.9697 - val_loss: 2.9547 - val_acc: 0.8000\n",
            "Epoch 404/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0157 - acc: 0.9899 - val_loss: 3.0101 - val_acc: 0.8000\n",
            "Epoch 405/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0359 - acc: 0.9899 - val_loss: 3.0078 - val_acc: 0.8000\n",
            "Epoch 406/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0346 - acc: 0.9899 - val_loss: 3.0016 - val_acc: 0.8000\n",
            "Epoch 407/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0387 - acc: 0.9697 - val_loss: 2.8730 - val_acc: 0.8000\n",
            "Epoch 408/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0453 - acc: 0.9899 - val_loss: 2.7400 - val_acc: 0.8000\n",
            "Epoch 409/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0469 - acc: 0.9697 - val_loss: 2.6521 - val_acc: 0.8000\n",
            "Epoch 410/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0252 - acc: 0.9899 - val_loss: 2.5864 - val_acc: 0.8400\n",
            "Epoch 411/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0314 - acc: 0.9899 - val_loss: 2.5705 - val_acc: 0.8400\n",
            "Epoch 412/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0323 - acc: 0.9798 - val_loss: 2.5945 - val_acc: 0.8400\n",
            "Epoch 413/1000\n",
            "99/99 [==============================] - 0s 363us/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 2.6498 - val_acc: 0.8400\n",
            "Epoch 414/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0448 - acc: 0.9697 - val_loss: 2.6715 - val_acc: 0.8400\n",
            "Epoch 415/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0234 - acc: 0.9899 - val_loss: 2.6696 - val_acc: 0.8000\n",
            "Epoch 416/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0320 - acc: 0.9899 - val_loss: 2.6816 - val_acc: 0.8000\n",
            "Epoch 417/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0547 - acc: 0.9798 - val_loss: 2.9235 - val_acc: 0.7600\n",
            "Epoch 418/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0220 - acc: 0.9899 - val_loss: 3.1381 - val_acc: 0.7200\n",
            "Epoch 419/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0302 - acc: 0.9899 - val_loss: 3.3157 - val_acc: 0.7200\n",
            "Epoch 420/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 3.3791 - val_acc: 0.7200\n",
            "Epoch 421/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0440 - acc: 0.9798 - val_loss: 3.3299 - val_acc: 0.7600\n",
            "Epoch 422/1000\n",
            "99/99 [==============================] - 0s 307us/sample - loss: 0.0413 - acc: 0.9798 - val_loss: 3.2472 - val_acc: 0.7600\n",
            "Epoch 423/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0502 - acc: 0.9798 - val_loss: 3.0460 - val_acc: 0.7600\n",
            "Epoch 424/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0674 - acc: 0.9798 - val_loss: 2.9627 - val_acc: 0.8000\n",
            "Epoch 425/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0778 - acc: 0.9495 - val_loss: 3.0969 - val_acc: 0.7600\n",
            "Epoch 426/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0475 - acc: 0.9697 - val_loss: 3.2667 - val_acc: 0.7200\n",
            "Epoch 427/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0550 - acc: 0.9798 - val_loss: 3.3171 - val_acc: 0.7200\n",
            "Epoch 428/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0686 - acc: 0.9697 - val_loss: 3.1315 - val_acc: 0.7200\n",
            "Epoch 429/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0550 - acc: 0.9798 - val_loss: 2.9453 - val_acc: 0.6800\n",
            "Epoch 430/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0697 - acc: 0.9798 - val_loss: 2.7223 - val_acc: 0.7600\n",
            "Epoch 431/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0537 - acc: 0.9798 - val_loss: 2.5121 - val_acc: 0.8000\n",
            "Epoch 432/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0868 - acc: 0.9596 - val_loss: 2.5936 - val_acc: 0.8000\n",
            "Epoch 433/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0567 - acc: 0.9798 - val_loss: 2.7816 - val_acc: 0.8000\n",
            "Epoch 434/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0836 - acc: 0.9495 - val_loss: 3.0152 - val_acc: 0.7600\n",
            "Epoch 435/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0245 - acc: 0.9899 - val_loss: 3.2507 - val_acc: 0.7600\n",
            "Epoch 436/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0813 - acc: 0.9697 - val_loss: 3.3398 - val_acc: 0.7200\n",
            "Epoch 437/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 3.3831 - val_acc: 0.6800\n",
            "Epoch 438/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0620 - acc: 0.9798 - val_loss: 3.3290 - val_acc: 0.6800\n",
            "Epoch 439/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0381 - acc: 0.9697 - val_loss: 3.2654 - val_acc: 0.6800\n",
            "Epoch 440/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 3.2365 - val_acc: 0.7200\n",
            "Epoch 441/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0488 - acc: 0.9798 - val_loss: 3.2399 - val_acc: 0.7200\n",
            "Epoch 442/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0351 - acc: 0.9899 - val_loss: 3.2852 - val_acc: 0.7200\n",
            "Epoch 443/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0221 - acc: 0.9899 - val_loss: 3.2967 - val_acc: 0.7600\n",
            "Epoch 444/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.1043 - acc: 0.9495 - val_loss: 3.0758 - val_acc: 0.7600\n",
            "Epoch 445/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0734 - acc: 0.9697 - val_loss: 2.9276 - val_acc: 0.7200\n",
            "Epoch 446/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0345 - acc: 0.9798 - val_loss: 2.8400 - val_acc: 0.7600\n",
            "Epoch 447/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0291 - acc: 0.9899 - val_loss: 2.7858 - val_acc: 0.7600\n",
            "Epoch 448/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0255 - acc: 0.9899 - val_loss: 2.7821 - val_acc: 0.7600\n",
            "Epoch 449/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 2.8354 - val_acc: 0.7200\n",
            "Epoch 450/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0443 - acc: 0.9798 - val_loss: 2.8931 - val_acc: 0.7200\n",
            "Epoch 451/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0817 - acc: 0.9697 - val_loss: 2.9513 - val_acc: 0.7600\n",
            "Epoch 452/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0435 - acc: 0.9798 - val_loss: 2.9715 - val_acc: 0.7600\n",
            "Epoch 453/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0340 - acc: 0.9798 - val_loss: 3.0098 - val_acc: 0.7600\n",
            "Epoch 454/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0304 - acc: 0.9899 - val_loss: 3.0401 - val_acc: 0.8000\n",
            "Epoch 455/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0321 - acc: 0.9899 - val_loss: 3.0533 - val_acc: 0.8000\n",
            "Epoch 456/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0187 - acc: 0.9899 - val_loss: 3.0607 - val_acc: 0.8000\n",
            "Epoch 457/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0300 - acc: 0.9899 - val_loss: 3.0612 - val_acc: 0.8000\n",
            "Epoch 458/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0257 - acc: 0.9899 - val_loss: 3.0805 - val_acc: 0.8000\n",
            "Epoch 459/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0434 - acc: 0.9697 - val_loss: 3.1174 - val_acc: 0.8000\n",
            "Epoch 460/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0226 - acc: 0.9899 - val_loss: 3.1634 - val_acc: 0.7600\n",
            "Epoch 461/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0643 - acc: 0.9495 - val_loss: 3.2253 - val_acc: 0.7200\n",
            "Epoch 462/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0355 - acc: 0.9798 - val_loss: 3.2788 - val_acc: 0.7200\n",
            "Epoch 463/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 3.2987 - val_acc: 0.6800\n",
            "Epoch 464/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0606 - acc: 0.9697 - val_loss: 3.1785 - val_acc: 0.7200\n",
            "Epoch 465/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0288 - acc: 0.9899 - val_loss: 3.0477 - val_acc: 0.8400\n",
            "Epoch 466/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0214 - acc: 0.9899 - val_loss: 2.9305 - val_acc: 0.8400\n",
            "Epoch 467/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0754 - acc: 0.9697 - val_loss: 2.9163 - val_acc: 0.8000\n",
            "Epoch 468/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0407 - acc: 0.9798 - val_loss: 2.9543 - val_acc: 0.8000\n",
            "Epoch 469/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0426 - acc: 0.9798 - val_loss: 2.9709 - val_acc: 0.7600\n",
            "Epoch 470/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0370 - acc: 0.9697 - val_loss: 2.9718 - val_acc: 0.7600\n",
            "Epoch 471/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0282 - acc: 0.9899 - val_loss: 2.9470 - val_acc: 0.7600\n",
            "Epoch 472/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0310 - acc: 0.9798 - val_loss: 2.9393 - val_acc: 0.8000\n",
            "Epoch 473/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0289 - acc: 0.9798 - val_loss: 2.9526 - val_acc: 0.8000\n",
            "Epoch 474/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0685 - acc: 0.9697 - val_loss: 2.8070 - val_acc: 0.7600\n",
            "Epoch 475/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0248 - acc: 0.9899 - val_loss: 2.6939 - val_acc: 0.8000\n",
            "Epoch 476/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0206 - acc: 0.9899 - val_loss: 2.6252 - val_acc: 0.8000\n",
            "Epoch 477/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0733 - acc: 0.9697 - val_loss: 2.6653 - val_acc: 0.8000\n",
            "Epoch 478/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0386 - acc: 0.9798 - val_loss: 2.7584 - val_acc: 0.8000\n",
            "Epoch 479/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0343 - acc: 0.9899 - val_loss: 2.8790 - val_acc: 0.8000\n",
            "Epoch 480/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0610 - acc: 0.9899 - val_loss: 2.9694 - val_acc: 0.8000\n",
            "Epoch 481/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0313 - acc: 0.9899 - val_loss: 3.0381 - val_acc: 0.8000\n",
            "Epoch 482/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0491 - acc: 0.9798 - val_loss: 2.9871 - val_acc: 0.8000\n",
            "Epoch 483/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0361 - acc: 0.9697 - val_loss: 2.9173 - val_acc: 0.8000\n",
            "Epoch 484/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0346 - acc: 0.9798 - val_loss: 2.8624 - val_acc: 0.8000\n",
            "Epoch 485/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0202 - acc: 0.9899 - val_loss: 2.8319 - val_acc: 0.7600\n",
            "Epoch 486/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0577 - acc: 0.9697 - val_loss: 2.8609 - val_acc: 0.7600\n",
            "Epoch 487/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0838 - acc: 0.9596 - val_loss: 2.9389 - val_acc: 0.7600\n",
            "Epoch 488/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0329 - acc: 0.9899 - val_loss: 2.9977 - val_acc: 0.8000\n",
            "Epoch 489/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0591 - acc: 0.9697 - val_loss: 3.0033 - val_acc: 0.8000\n",
            "Epoch 490/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 3.0071 - val_acc: 0.8000\n",
            "Epoch 491/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0467 - acc: 0.9697 - val_loss: 2.9371 - val_acc: 0.8000\n",
            "Epoch 492/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0395 - acc: 0.9899 - val_loss: 2.8841 - val_acc: 0.8000\n",
            "Epoch 493/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0317 - acc: 0.9798 - val_loss: 2.8329 - val_acc: 0.8000\n",
            "Epoch 494/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0374 - acc: 0.9798 - val_loss: 2.7877 - val_acc: 0.7600\n",
            "Epoch 495/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0303 - acc: 0.9798 - val_loss: 2.7415 - val_acc: 0.7600\n",
            "Epoch 496/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0410 - acc: 0.9798 - val_loss: 2.7300 - val_acc: 0.7600\n",
            "Epoch 497/1000\n",
            "99/99 [==============================] - 0s 351us/sample - loss: 0.0426 - acc: 0.9798 - val_loss: 2.7160 - val_acc: 0.7600\n",
            "Epoch 498/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0284 - acc: 0.9798 - val_loss: 2.6948 - val_acc: 0.7600\n",
            "Epoch 499/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 2.7020 - val_acc: 0.8000\n",
            "Epoch 500/1000\n",
            "99/99 [==============================] - 0s 341us/sample - loss: 0.0481 - acc: 0.9899 - val_loss: 2.7577 - val_acc: 0.8000\n",
            "Epoch 501/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0295 - acc: 0.9798 - val_loss: 2.8424 - val_acc: 0.7600\n",
            "Epoch 502/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0347 - acc: 0.9899 - val_loss: 2.9131 - val_acc: 0.7600\n",
            "Epoch 503/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0465 - acc: 0.9798 - val_loss: 2.9729 - val_acc: 0.7600\n",
            "Epoch 504/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0629 - acc: 0.9697 - val_loss: 3.0134 - val_acc: 0.7600\n",
            "Epoch 505/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0530 - acc: 0.9495 - val_loss: 2.9359 - val_acc: 0.7600\n",
            "Epoch 506/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0341 - acc: 0.9899 - val_loss: 2.8749 - val_acc: 0.8400\n",
            "Epoch 507/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0368 - acc: 0.9798 - val_loss: 2.8162 - val_acc: 0.8400\n",
            "Epoch 508/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0341 - acc: 0.9899 - val_loss: 2.7577 - val_acc: 0.8400\n",
            "Epoch 509/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0687 - acc: 0.9697 - val_loss: 2.6890 - val_acc: 0.8400\n",
            "Epoch 510/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0601 - acc: 0.9697 - val_loss: 2.7099 - val_acc: 0.8400\n",
            "Epoch 511/1000\n",
            "99/99 [==============================] - 0s 308us/sample - loss: 0.0477 - acc: 0.9899 - val_loss: 2.7837 - val_acc: 0.8400\n",
            "Epoch 512/1000\n",
            "99/99 [==============================] - 0s 362us/sample - loss: 0.0419 - acc: 0.9697 - val_loss: 2.8850 - val_acc: 0.8000\n",
            "Epoch 513/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0417 - acc: 0.9697 - val_loss: 3.0006 - val_acc: 0.8000\n",
            "Epoch 514/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0598 - acc: 0.9596 - val_loss: 3.1098 - val_acc: 0.7600\n",
            "Epoch 515/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 3.1984 - val_acc: 0.7200\n",
            "Epoch 516/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0581 - acc: 0.9697 - val_loss: 3.1311 - val_acc: 0.7200\n",
            "Epoch 517/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0588 - acc: 0.9697 - val_loss: 2.9585 - val_acc: 0.8000\n",
            "Epoch 518/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0421 - acc: 0.9798 - val_loss: 2.8330 - val_acc: 0.8000\n",
            "Epoch 519/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0317 - acc: 0.9798 - val_loss: 2.7651 - val_acc: 0.8400\n",
            "Epoch 520/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0344 - acc: 0.9798 - val_loss: 2.7553 - val_acc: 0.8400\n",
            "Epoch 521/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0502 - acc: 0.9798 - val_loss: 2.8047 - val_acc: 0.8400\n",
            "Epoch 522/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0227 - acc: 0.9899 - val_loss: 2.8563 - val_acc: 0.8400\n",
            "Epoch 523/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0367 - acc: 0.9798 - val_loss: 2.9217 - val_acc: 0.8400\n",
            "Epoch 524/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0401 - acc: 0.9798 - val_loss: 2.8739 - val_acc: 0.8400\n",
            "Epoch 525/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0394 - acc: 0.9798 - val_loss: 2.8660 - val_acc: 0.8400\n",
            "Epoch 526/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0379 - acc: 0.9798 - val_loss: 2.8643 - val_acc: 0.8400\n",
            "Epoch 527/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0404 - acc: 0.9899 - val_loss: 2.8117 - val_acc: 0.8400\n",
            "Epoch 528/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0404 - acc: 0.9697 - val_loss: 2.7528 - val_acc: 0.8000\n",
            "Epoch 529/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0500 - acc: 0.9798 - val_loss: 2.6710 - val_acc: 0.8000\n",
            "Epoch 530/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 2.5982 - val_acc: 0.8000\n",
            "Epoch 531/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0593 - acc: 0.9697 - val_loss: 2.5586 - val_acc: 0.8000\n",
            "Epoch 532/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0290 - acc: 0.9899 - val_loss: 2.5454 - val_acc: 0.8000\n",
            "Epoch 533/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0895 - acc: 0.9495 - val_loss: 2.6339 - val_acc: 0.8000\n",
            "Epoch 534/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0422 - acc: 0.9697 - val_loss: 2.7395 - val_acc: 0.8000\n",
            "Epoch 535/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0307 - acc: 0.9899 - val_loss: 2.8233 - val_acc: 0.7600\n",
            "Epoch 536/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0382 - acc: 0.9798 - val_loss: 2.8324 - val_acc: 0.7600\n",
            "Epoch 537/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0366 - acc: 0.9798 - val_loss: 2.7991 - val_acc: 0.7600\n",
            "Epoch 538/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 2.7294 - val_acc: 0.8000\n",
            "Epoch 539/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 2.6507 - val_acc: 0.8400\n",
            "Epoch 540/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0366 - acc: 0.9798 - val_loss: 2.5811 - val_acc: 0.8400\n",
            "Epoch 541/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0431 - acc: 0.9697 - val_loss: 2.5592 - val_acc: 0.8400\n",
            "Epoch 542/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0286 - acc: 0.9899 - val_loss: 2.5903 - val_acc: 0.8400\n",
            "Epoch 543/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0257 - acc: 0.9899 - val_loss: 2.6368 - val_acc: 0.8000\n",
            "Epoch 544/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0402 - acc: 0.9798 - val_loss: 2.6896 - val_acc: 0.8000\n",
            "Epoch 545/1000\n",
            "99/99 [==============================] - 0s 387us/sample - loss: 0.0285 - acc: 0.9798 - val_loss: 2.7604 - val_acc: 0.8000\n",
            "Epoch 546/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0599 - acc: 0.9596 - val_loss: 2.8158 - val_acc: 0.8000\n",
            "Epoch 547/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0254 - acc: 0.9899 - val_loss: 2.8851 - val_acc: 0.8000\n",
            "Epoch 548/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0207 - acc: 0.9899 - val_loss: 2.9453 - val_acc: 0.8000\n",
            "Epoch 549/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0278 - acc: 0.9899 - val_loss: 2.9706 - val_acc: 0.8000\n",
            "Epoch 550/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0323 - acc: 0.9798 - val_loss: 2.9666 - val_acc: 0.8000\n",
            "Epoch 551/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0443 - acc: 0.9899 - val_loss: 2.9215 - val_acc: 0.8000\n",
            "Epoch 552/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0301 - acc: 0.9899 - val_loss: 2.8812 - val_acc: 0.8000\n",
            "Epoch 553/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0402 - acc: 0.9798 - val_loss: 2.8516 - val_acc: 0.8000\n",
            "Epoch 554/1000\n",
            "99/99 [==============================] - 0s 307us/sample - loss: 0.0543 - acc: 0.9899 - val_loss: 2.8455 - val_acc: 0.8000\n",
            "Epoch 555/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0308 - acc: 0.9798 - val_loss: 2.8401 - val_acc: 0.8000\n",
            "Epoch 556/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0318 - acc: 0.9697 - val_loss: 2.8607 - val_acc: 0.8000\n",
            "Epoch 557/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0408 - acc: 0.9697 - val_loss: 2.8982 - val_acc: 0.8000\n",
            "Epoch 558/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0254 - acc: 0.9899 - val_loss: 2.9492 - val_acc: 0.8000\n",
            "Epoch 559/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0295 - acc: 0.9798 - val_loss: 3.0085 - val_acc: 0.7600\n",
            "Epoch 560/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0314 - acc: 0.9899 - val_loss: 3.0371 - val_acc: 0.7600\n",
            "Epoch 561/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0248 - acc: 0.9899 - val_loss: 3.0377 - val_acc: 0.7600\n",
            "Epoch 562/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0561 - acc: 0.9697 - val_loss: 3.0147 - val_acc: 0.7600\n",
            "Epoch 563/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0324 - acc: 0.9899 - val_loss: 2.9746 - val_acc: 0.8000\n",
            "Epoch 564/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0279 - acc: 0.9899 - val_loss: 2.9214 - val_acc: 0.8000\n",
            "Epoch 565/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0610 - acc: 0.9596 - val_loss: 2.8688 - val_acc: 0.8000\n",
            "Epoch 566/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0307 - acc: 0.9899 - val_loss: 2.8365 - val_acc: 0.8000\n",
            "Epoch 567/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0325 - acc: 0.9798 - val_loss: 2.7986 - val_acc: 0.8000\n",
            "Epoch 568/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0528 - acc: 0.9697 - val_loss: 2.7929 - val_acc: 0.8000\n",
            "Epoch 569/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 2.7987 - val_acc: 0.8000\n",
            "Epoch 570/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0339 - acc: 0.9899 - val_loss: 2.7931 - val_acc: 0.8000\n",
            "Epoch 571/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0277 - acc: 0.9899 - val_loss: 2.8117 - val_acc: 0.8000\n",
            "Epoch 572/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0231 - acc: 0.9899 - val_loss: 2.8353 - val_acc: 0.8000\n",
            "Epoch 573/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0244 - acc: 0.9899 - val_loss: 2.8412 - val_acc: 0.7600\n",
            "Epoch 574/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0280 - acc: 0.9899 - val_loss: 2.8437 - val_acc: 0.7600\n",
            "Epoch 575/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0321 - acc: 0.9798 - val_loss: 2.8071 - val_acc: 0.7600\n",
            "Epoch 576/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0578 - acc: 0.9596 - val_loss: 2.7466 - val_acc: 0.8400\n",
            "Epoch 577/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0418 - acc: 0.9798 - val_loss: 2.6855 - val_acc: 0.8400\n",
            "Epoch 578/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0219 - acc: 0.9899 - val_loss: 2.6410 - val_acc: 0.8400\n",
            "Epoch 579/1000\n",
            "99/99 [==============================] - 0s 346us/sample - loss: 0.0454 - acc: 0.9899 - val_loss: 2.6449 - val_acc: 0.8400\n",
            "Epoch 580/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0695 - acc: 0.9596 - val_loss: 2.7862 - val_acc: 0.8400\n",
            "Epoch 581/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0494 - acc: 0.9596 - val_loss: 2.9418 - val_acc: 0.8400\n",
            "Epoch 582/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0374 - acc: 0.9798 - val_loss: 3.1021 - val_acc: 0.8000\n",
            "Epoch 583/1000\n",
            "99/99 [==============================] - 0s 308us/sample - loss: 0.0455 - acc: 0.9798 - val_loss: 3.2237 - val_acc: 0.7600\n",
            "Epoch 584/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0860 - acc: 0.9495 - val_loss: 3.1319 - val_acc: 0.8000\n",
            "Epoch 585/1000\n",
            "99/99 [==============================] - 0s 357us/sample - loss: 0.0339 - acc: 0.9798 - val_loss: 3.0009 - val_acc: 0.8000\n",
            "Epoch 586/1000\n",
            "99/99 [==============================] - 0s 339us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 2.8847 - val_acc: 0.7600\n",
            "Epoch 587/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0364 - acc: 0.9899 - val_loss: 2.7735 - val_acc: 0.7600\n",
            "Epoch 588/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0607 - acc: 0.9798 - val_loss: 2.7815 - val_acc: 0.8000\n",
            "Epoch 589/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0340 - acc: 0.9899 - val_loss: 2.8080 - val_acc: 0.8000\n",
            "Epoch 590/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0690 - acc: 0.9697 - val_loss: 2.9995 - val_acc: 0.7600\n",
            "Epoch 591/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0291 - acc: 0.9899 - val_loss: 3.1894 - val_acc: 0.7600\n",
            "Epoch 592/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0264 - acc: 0.9798 - val_loss: 3.3447 - val_acc: 0.7600\n",
            "Epoch 593/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0665 - acc: 0.9596 - val_loss: 3.2981 - val_acc: 0.7600\n",
            "Epoch 594/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0490 - acc: 0.9798 - val_loss: 3.1797 - val_acc: 0.7600\n",
            "Epoch 595/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0591 - acc: 0.9697 - val_loss: 2.9921 - val_acc: 0.8000\n",
            "Epoch 596/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0351 - acc: 0.9798 - val_loss: 2.8995 - val_acc: 0.8000\n",
            "Epoch 597/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0377 - acc: 0.9798 - val_loss: 2.8984 - val_acc: 0.8000\n",
            "Epoch 598/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0296 - acc: 0.9899 - val_loss: 2.9084 - val_acc: 0.8000\n",
            "Epoch 599/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0648 - acc: 0.9697 - val_loss: 2.9184 - val_acc: 0.8000\n",
            "Epoch 600/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0629 - acc: 0.9798 - val_loss: 2.8750 - val_acc: 0.8000\n",
            "Epoch 601/1000\n",
            "99/99 [==============================] - 0s 368us/sample - loss: 0.0294 - acc: 0.9899 - val_loss: 2.8813 - val_acc: 0.8400\n",
            "Epoch 602/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0340 - acc: 0.9899 - val_loss: 2.9237 - val_acc: 0.8400\n",
            "Epoch 603/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0532 - acc: 0.9798 - val_loss: 2.9721 - val_acc: 0.8400\n",
            "Epoch 604/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0493 - acc: 0.9596 - val_loss: 2.9967 - val_acc: 0.8400\n",
            "Epoch 605/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0327 - acc: 0.9899 - val_loss: 2.9682 - val_acc: 0.8400\n",
            "Epoch 606/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0228 - acc: 0.9899 - val_loss: 2.9373 - val_acc: 0.8000\n",
            "Epoch 607/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0243 - acc: 0.9899 - val_loss: 2.8970 - val_acc: 0.8000\n",
            "Epoch 608/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0324 - acc: 0.9798 - val_loss: 2.8429 - val_acc: 0.8000\n",
            "Epoch 609/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0436 - acc: 0.9798 - val_loss: 2.7810 - val_acc: 0.8000\n",
            "Epoch 610/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0423 - acc: 0.9697 - val_loss: 2.7370 - val_acc: 0.8000\n",
            "Epoch 611/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0554 - acc: 0.9697 - val_loss: 2.6857 - val_acc: 0.8000\n",
            "Epoch 612/1000\n",
            "99/99 [==============================] - 0s 365us/sample - loss: 0.0312 - acc: 0.9798 - val_loss: 2.6676 - val_acc: 0.8000\n",
            "Epoch 613/1000\n",
            "99/99 [==============================] - 0s 354us/sample - loss: 0.0350 - acc: 0.9798 - val_loss: 2.7000 - val_acc: 0.8000\n",
            "Epoch 614/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0293 - acc: 0.9798 - val_loss: 2.7374 - val_acc: 0.8400\n",
            "Epoch 615/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0291 - acc: 0.9899 - val_loss: 2.7759 - val_acc: 0.8400\n",
            "Epoch 616/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0717 - acc: 0.9697 - val_loss: 2.7564 - val_acc: 0.7600\n",
            "Epoch 617/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0181 - acc: 0.9899 - val_loss: 2.7602 - val_acc: 0.7600\n",
            "Epoch 618/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0331 - acc: 0.9899 - val_loss: 2.7391 - val_acc: 0.8000\n",
            "Epoch 619/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0279 - acc: 0.9798 - val_loss: 2.7583 - val_acc: 0.8000\n",
            "Epoch 620/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0388 - acc: 0.9697 - val_loss: 2.8758 - val_acc: 0.8000\n",
            "Epoch 621/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0254 - acc: 0.9899 - val_loss: 3.0033 - val_acc: 0.8400\n",
            "Epoch 622/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0435 - acc: 0.9697 - val_loss: 3.0931 - val_acc: 0.8400\n",
            "Epoch 623/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 3.1716 - val_acc: 0.8400\n",
            "Epoch 624/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0294 - acc: 0.9899 - val_loss: 3.2069 - val_acc: 0.8400\n",
            "Epoch 625/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0318 - acc: 0.9899 - val_loss: 3.2322 - val_acc: 0.8400\n",
            "Epoch 626/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0837 - acc: 0.9697 - val_loss: 3.0086 - val_acc: 0.8400\n",
            "Epoch 627/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0318 - acc: 0.9798 - val_loss: 2.8223 - val_acc: 0.8000\n",
            "Epoch 628/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0270 - acc: 0.9899 - val_loss: 2.6782 - val_acc: 0.8000\n",
            "Epoch 629/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0763 - acc: 0.9798 - val_loss: 2.6287 - val_acc: 0.8000\n",
            "Epoch 630/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0282 - acc: 0.9899 - val_loss: 2.6026 - val_acc: 0.8000\n",
            "Epoch 631/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0839 - acc: 0.9798 - val_loss: 2.7039 - val_acc: 0.8000\n",
            "Epoch 632/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0533 - acc: 0.9798 - val_loss: 2.7575 - val_acc: 0.8400\n",
            "Epoch 633/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0348 - acc: 0.9798 - val_loss: 2.7939 - val_acc: 0.8400\n",
            "Epoch 634/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0648 - acc: 0.9596 - val_loss: 2.7656 - val_acc: 0.8400\n",
            "Epoch 635/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0416 - acc: 0.9697 - val_loss: 2.7228 - val_acc: 0.8400\n",
            "Epoch 636/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0356 - acc: 0.9899 - val_loss: 2.6573 - val_acc: 0.8400\n",
            "Epoch 637/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0585 - acc: 0.9697 - val_loss: 2.6075 - val_acc: 0.8400\n",
            "Epoch 638/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0576 - acc: 0.9697 - val_loss: 2.5861 - val_acc: 0.8400\n",
            "Epoch 639/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0580 - acc: 0.9798 - val_loss: 2.6193 - val_acc: 0.8000\n",
            "Epoch 640/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0888 - acc: 0.9495 - val_loss: 2.7111 - val_acc: 0.8000\n",
            "Epoch 641/1000\n",
            "99/99 [==============================] - 0s 353us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 2.8104 - val_acc: 0.8000\n",
            "Epoch 642/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0352 - acc: 0.9899 - val_loss: 2.9154 - val_acc: 0.7600\n",
            "Epoch 643/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0565 - acc: 0.9697 - val_loss: 2.9436 - val_acc: 0.7600\n",
            "Epoch 644/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0364 - acc: 0.9899 - val_loss: 2.9409 - val_acc: 0.7600\n",
            "Epoch 645/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0432 - acc: 0.9798 - val_loss: 2.9021 - val_acc: 0.8000\n",
            "Epoch 646/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0443 - acc: 0.9697 - val_loss: 2.8278 - val_acc: 0.8400\n",
            "Epoch 647/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0192 - acc: 0.9899 - val_loss: 2.7689 - val_acc: 0.8400\n",
            "Epoch 648/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0431 - acc: 0.9798 - val_loss: 2.7429 - val_acc: 0.8400\n",
            "Epoch 649/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0329 - acc: 0.9899 - val_loss: 2.7294 - val_acc: 0.8400\n",
            "Epoch 650/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0479 - acc: 0.9798 - val_loss: 2.7430 - val_acc: 0.8400\n",
            "Epoch 651/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0423 - acc: 0.9798 - val_loss: 2.7721 - val_acc: 0.8400\n",
            "Epoch 652/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0406 - acc: 0.9798 - val_loss: 2.7995 - val_acc: 0.8400\n",
            "Epoch 653/1000\n",
            "99/99 [==============================] - 0s 349us/sample - loss: 0.0297 - acc: 0.9899 - val_loss: 2.8261 - val_acc: 0.8400\n",
            "Epoch 654/1000\n",
            "99/99 [==============================] - 0s 341us/sample - loss: 0.0384 - acc: 0.9798 - val_loss: 2.8317 - val_acc: 0.7600\n",
            "Epoch 655/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0199 - acc: 0.9899 - val_loss: 2.8339 - val_acc: 0.7600\n",
            "Epoch 656/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0269 - acc: 0.9798 - val_loss: 2.8116 - val_acc: 0.7600\n",
            "Epoch 657/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0370 - acc: 0.9798 - val_loss: 2.7481 - val_acc: 0.8000\n",
            "Epoch 658/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0261 - acc: 0.9899 - val_loss: 2.6858 - val_acc: 0.8000\n",
            "Epoch 659/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0256 - acc: 0.9798 - val_loss: 2.6328 - val_acc: 0.8000\n",
            "Epoch 660/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0311 - acc: 0.9798 - val_loss: 2.5985 - val_acc: 0.8400\n",
            "Epoch 661/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0488 - acc: 0.9798 - val_loss: 2.6117 - val_acc: 0.8400\n",
            "Epoch 662/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0228 - acc: 0.9899 - val_loss: 2.6429 - val_acc: 0.8400\n",
            "Epoch 663/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0326 - acc: 0.9798 - val_loss: 2.6948 - val_acc: 0.8400\n",
            "Epoch 664/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0222 - acc: 0.9899 - val_loss: 2.7390 - val_acc: 0.8400\n",
            "Epoch 665/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0273 - acc: 0.9899 - val_loss: 2.7665 - val_acc: 0.8400\n",
            "Epoch 666/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0639 - acc: 0.9697 - val_loss: 2.7324 - val_acc: 0.8400\n",
            "Epoch 667/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0392 - acc: 0.9798 - val_loss: 2.6984 - val_acc: 0.8400\n",
            "Epoch 668/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0413 - acc: 0.9697 - val_loss: 2.6651 - val_acc: 0.8400\n",
            "Epoch 669/1000\n",
            "99/99 [==============================] - 0s 339us/sample - loss: 0.0172 - acc: 0.9899 - val_loss: 2.6358 - val_acc: 0.8400\n",
            "Epoch 670/1000\n",
            "99/99 [==============================] - 0s 355us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 2.6062 - val_acc: 0.8400\n",
            "Epoch 671/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0401 - acc: 0.9697 - val_loss: 2.6034 - val_acc: 0.8400\n",
            "Epoch 672/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0492 - acc: 0.9798 - val_loss: 2.6470 - val_acc: 0.8400\n",
            "Epoch 673/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0311 - acc: 0.9798 - val_loss: 2.7063 - val_acc: 0.8400\n",
            "Epoch 674/1000\n",
            "99/99 [==============================] - 0s 343us/sample - loss: 0.0218 - acc: 0.9899 - val_loss: 2.7663 - val_acc: 0.8000\n",
            "Epoch 675/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0189 - acc: 0.9899 - val_loss: 2.8172 - val_acc: 0.8000\n",
            "Epoch 676/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 2.8581 - val_acc: 0.8000\n",
            "Epoch 677/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0210 - acc: 0.9899 - val_loss: 2.8756 - val_acc: 0.8000\n",
            "Epoch 678/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0392 - acc: 0.9798 - val_loss: 2.8517 - val_acc: 0.8000\n",
            "Epoch 679/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0582 - acc: 0.9596 - val_loss: 2.7378 - val_acc: 0.8000\n",
            "Epoch 680/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0420 - acc: 0.9697 - val_loss: 2.6591 - val_acc: 0.8400\n",
            "Epoch 681/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0299 - acc: 0.9798 - val_loss: 2.6148 - val_acc: 0.8400\n",
            "Epoch 682/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0323 - acc: 0.9798 - val_loss: 2.6107 - val_acc: 0.8400\n",
            "Epoch 683/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0261 - acc: 0.9798 - val_loss: 2.6295 - val_acc: 0.8400\n",
            "Epoch 684/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0379 - acc: 0.9697 - val_loss: 2.7161 - val_acc: 0.8400\n",
            "Epoch 685/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0242 - acc: 0.9899 - val_loss: 2.8203 - val_acc: 0.8400\n",
            "Epoch 686/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0275 - acc: 0.9798 - val_loss: 2.9173 - val_acc: 0.8400\n",
            "Epoch 687/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0355 - acc: 0.9798 - val_loss: 3.0091 - val_acc: 0.8400\n",
            "Epoch 688/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0297 - acc: 0.9798 - val_loss: 3.0767 - val_acc: 0.8000\n",
            "Epoch 689/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0504 - acc: 0.9899 - val_loss: 3.1119 - val_acc: 0.8000\n",
            "Epoch 690/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0431 - acc: 0.9899 - val_loss: 3.0764 - val_acc: 0.8000\n",
            "Epoch 691/1000\n",
            "99/99 [==============================] - 0s 308us/sample - loss: 0.0286 - acc: 0.9899 - val_loss: 3.0289 - val_acc: 0.8400\n",
            "Epoch 692/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0309 - acc: 0.9798 - val_loss: 2.9795 - val_acc: 0.8400\n",
            "Epoch 693/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0598 - acc: 0.9798 - val_loss: 2.9677 - val_acc: 0.8400\n",
            "Epoch 694/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 2.9691 - val_acc: 0.8400\n",
            "Epoch 695/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0277 - acc: 0.9899 - val_loss: 2.9953 - val_acc: 0.8400\n",
            "Epoch 696/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0324 - acc: 0.9697 - val_loss: 3.0332 - val_acc: 0.8400\n",
            "Epoch 697/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0234 - acc: 0.9798 - val_loss: 3.0718 - val_acc: 0.8400\n",
            "Epoch 698/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0272 - acc: 0.9899 - val_loss: 3.0974 - val_acc: 0.8400\n",
            "Epoch 699/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0323 - acc: 0.9899 - val_loss: 3.0966 - val_acc: 0.8400\n",
            "Epoch 700/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0199 - acc: 0.9899 - val_loss: 3.0862 - val_acc: 0.8400\n",
            "Epoch 701/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0217 - acc: 0.9899 - val_loss: 3.0522 - val_acc: 0.8000\n",
            "Epoch 702/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0192 - acc: 0.9899 - val_loss: 3.0218 - val_acc: 0.8000\n",
            "Epoch 703/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0339 - acc: 0.9697 - val_loss: 2.9781 - val_acc: 0.8000\n",
            "Epoch 704/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0215 - acc: 0.9899 - val_loss: 2.9443 - val_acc: 0.8000\n",
            "Epoch 705/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0302 - acc: 0.9899 - val_loss: 2.9174 - val_acc: 0.8400\n",
            "Epoch 706/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0200 - acc: 0.9899 - val_loss: 2.9017 - val_acc: 0.8400\n",
            "Epoch 707/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0273 - acc: 0.9798 - val_loss: 2.8979 - val_acc: 0.8400\n",
            "Epoch 708/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0334 - acc: 0.9798 - val_loss: 2.9094 - val_acc: 0.8400\n",
            "Epoch 709/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0219 - acc: 0.9899 - val_loss: 2.9225 - val_acc: 0.8400\n",
            "Epoch 710/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 2.9471 - val_acc: 0.8400\n",
            "Epoch 711/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0246 - acc: 0.9899 - val_loss: 2.9579 - val_acc: 0.8400\n",
            "Epoch 712/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0192 - acc: 0.9899 - val_loss: 2.9568 - val_acc: 0.8400\n",
            "Epoch 713/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0371 - acc: 0.9697 - val_loss: 2.9656 - val_acc: 0.8400\n",
            "Epoch 714/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0237 - acc: 0.9899 - val_loss: 2.9358 - val_acc: 0.8400\n",
            "Epoch 715/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0381 - acc: 0.9798 - val_loss: 2.9093 - val_acc: 0.8000\n",
            "Epoch 716/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0256 - acc: 0.9798 - val_loss: 2.8757 - val_acc: 0.8000\n",
            "Epoch 717/1000\n",
            "99/99 [==============================] - 0s 334us/sample - loss: 0.0198 - acc: 0.9899 - val_loss: 2.8541 - val_acc: 0.8000\n",
            "Epoch 718/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0498 - acc: 0.9697 - val_loss: 2.8293 - val_acc: 0.8400\n",
            "Epoch 719/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0603 - acc: 0.9596 - val_loss: 2.8039 - val_acc: 0.8400\n",
            "Epoch 720/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0252 - acc: 0.9899 - val_loss: 2.8060 - val_acc: 0.8000\n",
            "Epoch 721/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0364 - acc: 0.9899 - val_loss: 2.8042 - val_acc: 0.8000\n",
            "Epoch 722/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0346 - acc: 0.9798 - val_loss: 2.7974 - val_acc: 0.8000\n",
            "Epoch 723/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 2.7836 - val_acc: 0.8000\n",
            "Epoch 724/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0600 - acc: 0.9697 - val_loss: 2.8243 - val_acc: 0.8000\n",
            "Epoch 725/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0393 - acc: 0.9798 - val_loss: 2.8982 - val_acc: 0.8000\n",
            "Epoch 726/1000\n",
            "99/99 [==============================] - 0s 410us/sample - loss: 0.0356 - acc: 0.9697 - val_loss: 2.9647 - val_acc: 0.8000\n",
            "Epoch 727/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0193 - acc: 0.9899 - val_loss: 3.0360 - val_acc: 0.8000\n",
            "Epoch 728/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 3.0983 - val_acc: 0.8000\n",
            "Epoch 729/1000\n",
            "99/99 [==============================] - 0s 345us/sample - loss: 0.0305 - acc: 0.9798 - val_loss: 3.0894 - val_acc: 0.8000\n",
            "Epoch 730/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0448 - acc: 0.9697 - val_loss: 3.0084 - val_acc: 0.8000\n",
            "Epoch 731/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0211 - acc: 0.9798 - val_loss: 2.9600 - val_acc: 0.8000\n",
            "Epoch 732/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 2.9362 - val_acc: 0.7600\n",
            "Epoch 733/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0347 - acc: 0.9899 - val_loss: 2.9288 - val_acc: 0.7600\n",
            "Epoch 734/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0191 - acc: 0.9899 - val_loss: 2.9368 - val_acc: 0.8000\n",
            "Epoch 735/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0347 - acc: 0.9798 - val_loss: 2.9343 - val_acc: 0.8000\n",
            "Epoch 736/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0398 - acc: 0.9798 - val_loss: 2.9160 - val_acc: 0.8000\n",
            "Epoch 737/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0344 - acc: 0.9798 - val_loss: 2.9094 - val_acc: 0.8000\n",
            "Epoch 738/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0353 - acc: 0.9798 - val_loss: 2.9371 - val_acc: 0.8400\n",
            "Epoch 739/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0242 - acc: 0.9899 - val_loss: 2.9686 - val_acc: 0.8400\n",
            "Epoch 740/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0195 - acc: 0.9899 - val_loss: 3.0125 - val_acc: 0.8000\n",
            "Epoch 741/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0300 - acc: 0.9899 - val_loss: 3.0316 - val_acc: 0.8000\n",
            "Epoch 742/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0360 - acc: 0.9899 - val_loss: 3.0102 - val_acc: 0.8000\n",
            "Epoch 743/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0280 - acc: 0.9899 - val_loss: 2.9786 - val_acc: 0.8400\n",
            "Epoch 744/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0232 - acc: 0.9899 - val_loss: 2.9397 - val_acc: 0.8400\n",
            "Epoch 745/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0399 - acc: 0.9798 - val_loss: 2.9229 - val_acc: 0.8000\n",
            "Epoch 746/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 2.9177 - val_acc: 0.8000\n",
            "Epoch 747/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0305 - acc: 0.9899 - val_loss: 2.9089 - val_acc: 0.8000\n",
            "Epoch 748/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0222 - acc: 0.9899 - val_loss: 2.9079 - val_acc: 0.8000\n",
            "Epoch 749/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 2.9050 - val_acc: 0.8000\n",
            "Epoch 750/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0294 - acc: 0.9798 - val_loss: 2.8901 - val_acc: 0.8000\n",
            "Epoch 751/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0337 - acc: 0.9899 - val_loss: 2.8821 - val_acc: 0.8000\n",
            "Epoch 752/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0282 - acc: 0.9899 - val_loss: 2.9014 - val_acc: 0.7600\n",
            "Epoch 753/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0276 - acc: 0.9899 - val_loss: 2.9233 - val_acc: 0.7600\n",
            "Epoch 754/1000\n",
            "99/99 [==============================] - 0s 342us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 2.9377 - val_acc: 0.7600\n",
            "Epoch 755/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0211 - acc: 0.9899 - val_loss: 2.9293 - val_acc: 0.8000\n",
            "Epoch 756/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0385 - acc: 0.9798 - val_loss: 2.9092 - val_acc: 0.8000\n",
            "Epoch 757/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0201 - acc: 0.9899 - val_loss: 2.8865 - val_acc: 0.8400\n",
            "Epoch 758/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0247 - acc: 0.9899 - val_loss: 2.8659 - val_acc: 0.8400\n",
            "Epoch 759/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0418 - acc: 0.9798 - val_loss: 2.8569 - val_acc: 0.8400\n",
            "Epoch 760/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0276 - acc: 0.9899 - val_loss: 2.8734 - val_acc: 0.8400\n",
            "Epoch 761/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0320 - acc: 0.9697 - val_loss: 2.9155 - val_acc: 0.8400\n",
            "Epoch 762/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0395 - acc: 0.9798 - val_loss: 2.9669 - val_acc: 0.8400\n",
            "Epoch 763/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0321 - acc: 0.9899 - val_loss: 2.9858 - val_acc: 0.8000\n",
            "Epoch 764/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 2.9960 - val_acc: 0.8000\n",
            "Epoch 765/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0320 - acc: 0.9697 - val_loss: 2.9801 - val_acc: 0.8000\n",
            "Epoch 766/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0312 - acc: 0.9798 - val_loss: 2.9550 - val_acc: 0.8000\n",
            "Epoch 767/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0264 - acc: 0.9798 - val_loss: 2.9226 - val_acc: 0.8000\n",
            "Epoch 768/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0157 - acc: 0.9899 - val_loss: 2.9173 - val_acc: 0.8000\n",
            "Epoch 769/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0307 - acc: 0.9798 - val_loss: 2.9122 - val_acc: 0.8000\n",
            "Epoch 770/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0341 - acc: 0.9798 - val_loss: 2.9049 - val_acc: 0.8000\n",
            "Epoch 771/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0313 - acc: 0.9798 - val_loss: 2.9224 - val_acc: 0.8000\n",
            "Epoch 772/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0238 - acc: 0.9899 - val_loss: 2.9471 - val_acc: 0.8400\n",
            "Epoch 773/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0251 - acc: 0.9798 - val_loss: 2.9867 - val_acc: 0.8400\n",
            "Epoch 774/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0446 - acc: 0.9798 - val_loss: 3.0348 - val_acc: 0.8000\n",
            "Epoch 775/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0301 - acc: 0.9798 - val_loss: 3.0702 - val_acc: 0.8000\n",
            "Epoch 776/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0275 - acc: 0.9899 - val_loss: 3.0972 - val_acc: 0.8000\n",
            "Epoch 777/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0237 - acc: 0.9899 - val_loss: 3.1140 - val_acc: 0.8000\n",
            "Epoch 778/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0392 - acc: 0.9798 - val_loss: 3.0879 - val_acc: 0.8000\n",
            "Epoch 779/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0227 - acc: 0.9899 - val_loss: 3.0348 - val_acc: 0.8000\n",
            "Epoch 780/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0328 - acc: 0.9899 - val_loss: 3.0121 - val_acc: 0.8000\n",
            "Epoch 781/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 2.9829 - val_acc: 0.8400\n",
            "Epoch 782/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0231 - acc: 0.9899 - val_loss: 2.9730 - val_acc: 0.8400\n",
            "Epoch 783/1000\n",
            "99/99 [==============================] - 0s 352us/sample - loss: 0.0257 - acc: 0.9899 - val_loss: 2.9472 - val_acc: 0.8400\n",
            "Epoch 784/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0205 - acc: 0.9899 - val_loss: 2.9190 - val_acc: 0.8400\n",
            "Epoch 785/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0293 - acc: 0.9899 - val_loss: 2.8932 - val_acc: 0.8400\n",
            "Epoch 786/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0412 - acc: 0.9798 - val_loss: 2.8723 - val_acc: 0.8400\n",
            "Epoch 787/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 2.8910 - val_acc: 0.8400\n",
            "Epoch 788/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0239 - acc: 0.9899 - val_loss: 2.9130 - val_acc: 0.8400\n",
            "Epoch 789/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0225 - acc: 0.9798 - val_loss: 2.9475 - val_acc: 0.8400\n",
            "Epoch 790/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 2.9799 - val_acc: 0.8400\n",
            "Epoch 791/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0151 - acc: 0.9899 - val_loss: 3.0156 - val_acc: 0.8400\n",
            "Epoch 792/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0343 - acc: 0.9697 - val_loss: 3.0591 - val_acc: 0.8000\n",
            "Epoch 793/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 3.0957 - val_acc: 0.8000\n",
            "Epoch 794/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0195 - acc: 0.9899 - val_loss: 3.1202 - val_acc: 0.8000\n",
            "Epoch 795/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0196 - acc: 0.9899 - val_loss: 3.1282 - val_acc: 0.8000\n",
            "Epoch 796/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0549 - acc: 0.9697 - val_loss: 3.0741 - val_acc: 0.7600\n",
            "Epoch 797/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0210 - acc: 0.9899 - val_loss: 3.0107 - val_acc: 0.7600\n",
            "Epoch 798/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0335 - acc: 0.9798 - val_loss: 2.9335 - val_acc: 0.7600\n",
            "Epoch 799/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0313 - acc: 0.9798 - val_loss: 2.8820 - val_acc: 0.7600\n",
            "Epoch 800/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0294 - acc: 0.9798 - val_loss: 2.8655 - val_acc: 0.7600\n",
            "Epoch 801/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0424 - acc: 0.9798 - val_loss: 2.8700 - val_acc: 0.7600\n",
            "Epoch 802/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0241 - acc: 0.9899 - val_loss: 2.8785 - val_acc: 0.7600\n",
            "Epoch 803/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0288 - acc: 0.9798 - val_loss: 2.9109 - val_acc: 0.8000\n",
            "Epoch 804/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 2.9520 - val_acc: 0.8000\n",
            "Epoch 805/1000\n",
            "99/99 [==============================] - 0s 338us/sample - loss: 0.0409 - acc: 0.9798 - val_loss: 3.0016 - val_acc: 0.8000\n",
            "Epoch 806/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 3.0396 - val_acc: 0.8000\n",
            "Epoch 807/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0184 - acc: 0.9899 - val_loss: 3.0660 - val_acc: 0.8000\n",
            "Epoch 808/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0284 - acc: 0.9798 - val_loss: 3.0513 - val_acc: 0.8000\n",
            "Epoch 809/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0174 - acc: 0.9899 - val_loss: 3.0421 - val_acc: 0.8000\n",
            "Epoch 810/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0454 - acc: 0.9697 - val_loss: 3.0022 - val_acc: 0.8400\n",
            "Epoch 811/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0300 - acc: 0.9899 - val_loss: 2.9134 - val_acc: 0.8400\n",
            "Epoch 812/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0272 - acc: 0.9899 - val_loss: 2.8455 - val_acc: 0.8400\n",
            "Epoch 813/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0269 - acc: 0.9899 - val_loss: 2.7867 - val_acc: 0.8400\n",
            "Epoch 814/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0367 - acc: 0.9798 - val_loss: 2.7675 - val_acc: 0.8400\n",
            "Epoch 815/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0264 - acc: 0.9899 - val_loss: 2.7621 - val_acc: 0.8400\n",
            "Epoch 816/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0407 - acc: 0.9697 - val_loss: 2.7937 - val_acc: 0.8400\n",
            "Epoch 817/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0385 - acc: 0.9697 - val_loss: 2.8606 - val_acc: 0.8400\n",
            "Epoch 818/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0229 - acc: 0.9798 - val_loss: 2.9157 - val_acc: 0.8000\n",
            "Epoch 819/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0393 - acc: 0.9899 - val_loss: 2.9162 - val_acc: 0.8000\n",
            "Epoch 820/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0207 - acc: 0.9899 - val_loss: 2.9060 - val_acc: 0.8000\n",
            "Epoch 821/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0217 - acc: 0.9899 - val_loss: 2.8796 - val_acc: 0.8000\n",
            "Epoch 822/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0234 - acc: 0.9899 - val_loss: 2.8575 - val_acc: 0.8000\n",
            "Epoch 823/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0268 - acc: 0.9899 - val_loss: 2.8655 - val_acc: 0.8000\n",
            "Epoch 824/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0299 - acc: 0.9899 - val_loss: 2.8757 - val_acc: 0.8000\n",
            "Epoch 825/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0317 - acc: 0.9899 - val_loss: 2.8937 - val_acc: 0.8400\n",
            "Epoch 826/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0220 - acc: 0.9899 - val_loss: 2.9247 - val_acc: 0.8400\n",
            "Epoch 827/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0317 - acc: 0.9798 - val_loss: 2.9650 - val_acc: 0.8400\n",
            "Epoch 828/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0262 - acc: 0.9899 - val_loss: 2.9829 - val_acc: 0.8400\n",
            "Epoch 829/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0401 - acc: 0.9697 - val_loss: 2.9589 - val_acc: 0.8400\n",
            "Epoch 830/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0563 - acc: 0.9596 - val_loss: 2.7806 - val_acc: 0.8400\n",
            "Epoch 831/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0325 - acc: 0.9899 - val_loss: 2.6536 - val_acc: 0.8000\n",
            "Epoch 832/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0217 - acc: 0.9899 - val_loss: 2.6084 - val_acc: 0.8000\n",
            "Epoch 833/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0656 - acc: 0.9596 - val_loss: 2.6456 - val_acc: 0.8000\n",
            "Epoch 834/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0401 - acc: 0.9798 - val_loss: 2.7411 - val_acc: 0.8000\n",
            "Epoch 835/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0515 - acc: 0.9697 - val_loss: 2.8660 - val_acc: 0.8000\n",
            "Epoch 836/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 2.9983 - val_acc: 0.8000\n",
            "Epoch 837/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 3.0800 - val_acc: 0.8000\n",
            "Epoch 838/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0360 - acc: 0.9899 - val_loss: 3.1109 - val_acc: 0.7600\n",
            "Epoch 839/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0541 - acc: 0.9798 - val_loss: 3.0290 - val_acc: 0.8400\n",
            "Epoch 840/1000\n",
            "99/99 [==============================] - 0s 350us/sample - loss: 0.0639 - acc: 0.9697 - val_loss: 2.9356 - val_acc: 0.8000\n",
            "Epoch 841/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 2.8794 - val_acc: 0.8000\n",
            "Epoch 842/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0542 - acc: 0.9596 - val_loss: 2.8732 - val_acc: 0.8000\n",
            "Epoch 843/1000\n",
            "99/99 [==============================] - 0s 347us/sample - loss: 0.0463 - acc: 0.9798 - val_loss: 2.9155 - val_acc: 0.8000\n",
            "Epoch 844/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0467 - acc: 0.9798 - val_loss: 3.0085 - val_acc: 0.7600\n",
            "Epoch 845/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 3.1049 - val_acc: 0.8000\n",
            "Epoch 846/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0228 - acc: 0.9798 - val_loss: 3.1988 - val_acc: 0.8000\n",
            "Epoch 847/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0254 - acc: 0.9899 - val_loss: 3.2626 - val_acc: 0.8000\n",
            "Epoch 848/1000\n",
            "99/99 [==============================] - 0s 355us/sample - loss: 0.0494 - acc: 0.9899 - val_loss: 3.2676 - val_acc: 0.8000\n",
            "Epoch 849/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0567 - acc: 0.9798 - val_loss: 3.1271 - val_acc: 0.8000\n",
            "Epoch 850/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 2.9791 - val_acc: 0.8000\n",
            "Epoch 851/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0292 - acc: 0.9899 - val_loss: 2.8943 - val_acc: 0.8000\n",
            "Epoch 852/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0454 - acc: 0.9697 - val_loss: 2.8709 - val_acc: 0.8000\n",
            "Epoch 853/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0332 - acc: 0.9899 - val_loss: 2.9375 - val_acc: 0.8000\n",
            "Epoch 854/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0410 - acc: 0.9697 - val_loss: 3.0505 - val_acc: 0.8000\n",
            "Epoch 855/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0312 - acc: 0.9899 - val_loss: 3.1602 - val_acc: 0.7600\n",
            "Epoch 856/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0347 - acc: 0.9697 - val_loss: 3.2579 - val_acc: 0.8000\n",
            "Epoch 857/1000\n",
            "99/99 [==============================] - 0s 340us/sample - loss: 0.0179 - acc: 0.9899 - val_loss: 3.3516 - val_acc: 0.8000\n",
            "Epoch 858/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0398 - acc: 0.9697 - val_loss: 3.3667 - val_acc: 0.8000\n",
            "Epoch 859/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0281 - acc: 0.9899 - val_loss: 3.3502 - val_acc: 0.8000\n",
            "Epoch 860/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0276 - acc: 0.9798 - val_loss: 3.2964 - val_acc: 0.8400\n",
            "Epoch 861/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0406 - acc: 0.9899 - val_loss: 3.1914 - val_acc: 0.8400\n",
            "Epoch 862/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0287 - acc: 0.9798 - val_loss: 3.1183 - val_acc: 0.8400\n",
            "Epoch 863/1000\n",
            "99/99 [==============================] - 0s 348us/sample - loss: 0.0436 - acc: 0.9697 - val_loss: 3.0633 - val_acc: 0.8400\n",
            "Epoch 864/1000\n",
            "99/99 [==============================] - 0s 342us/sample - loss: 0.0231 - acc: 0.9899 - val_loss: 3.0155 - val_acc: 0.8000\n",
            "Epoch 865/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0195 - acc: 0.9899 - val_loss: 2.9866 - val_acc: 0.8000\n",
            "Epoch 866/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0211 - acc: 0.9798 - val_loss: 2.9700 - val_acc: 0.8000\n",
            "Epoch 867/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0394 - acc: 0.9798 - val_loss: 2.9943 - val_acc: 0.8000\n",
            "Epoch 868/1000\n",
            "99/99 [==============================] - 0s 352us/sample - loss: 0.0324 - acc: 0.9798 - val_loss: 3.0181 - val_acc: 0.8000\n",
            "Epoch 869/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0274 - acc: 0.9899 - val_loss: 3.0376 - val_acc: 0.7600\n",
            "Epoch 870/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0272 - acc: 0.9798 - val_loss: 3.0383 - val_acc: 0.7600\n",
            "Epoch 871/1000\n",
            "99/99 [==============================] - 0s 346us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 3.0425 - val_acc: 0.8000\n",
            "Epoch 872/1000\n",
            "99/99 [==============================] - 0s 342us/sample - loss: 0.0303 - acc: 0.9798 - val_loss: 3.0325 - val_acc: 0.8000\n",
            "Epoch 873/1000\n",
            "99/99 [==============================] - 0s 329us/sample - loss: 0.0272 - acc: 0.9899 - val_loss: 3.0075 - val_acc: 0.8000\n",
            "Epoch 874/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 2.9765 - val_acc: 0.8000\n",
            "Epoch 875/1000\n",
            "99/99 [==============================] - 0s 370us/sample - loss: 0.0325 - acc: 0.9899 - val_loss: 2.9508 - val_acc: 0.8000\n",
            "Epoch 876/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0247 - acc: 0.9899 - val_loss: 2.9304 - val_acc: 0.8000\n",
            "Epoch 877/1000\n",
            "99/99 [==============================] - 0s 339us/sample - loss: 0.0180 - acc: 0.9899 - val_loss: 2.9100 - val_acc: 0.8000\n",
            "Epoch 878/1000\n",
            "99/99 [==============================] - 0s 328us/sample - loss: 0.0274 - acc: 0.9899 - val_loss: 2.9054 - val_acc: 0.8400\n",
            "Epoch 879/1000\n",
            "99/99 [==============================] - 0s 332us/sample - loss: 0.0587 - acc: 0.9798 - val_loss: 2.9069 - val_acc: 0.8400\n",
            "Epoch 880/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0192 - acc: 0.9899 - val_loss: 2.9228 - val_acc: 0.8400\n",
            "Epoch 881/1000\n",
            "99/99 [==============================] - 0s 345us/sample - loss: 0.0208 - acc: 0.9899 - val_loss: 2.9299 - val_acc: 0.8400\n",
            "Epoch 882/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 2.9365 - val_acc: 0.8400\n",
            "Epoch 883/1000\n",
            "99/99 [==============================] - 0s 341us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 2.9464 - val_acc: 0.8400\n",
            "Epoch 884/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 2.9617 - val_acc: 0.8400\n",
            "Epoch 885/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0326 - acc: 0.9899 - val_loss: 2.9431 - val_acc: 0.8400\n",
            "Epoch 886/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0407 - acc: 0.9899 - val_loss: 2.8904 - val_acc: 0.8400\n",
            "Epoch 887/1000\n",
            "99/99 [==============================] - 0s 345us/sample - loss: 0.0228 - acc: 0.9798 - val_loss: 2.8425 - val_acc: 0.8400\n",
            "Epoch 888/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0449 - acc: 0.9697 - val_loss: 2.8413 - val_acc: 0.8400\n",
            "Epoch 889/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0431 - acc: 0.9697 - val_loss: 2.8590 - val_acc: 0.8400\n",
            "Epoch 890/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0323 - acc: 0.9798 - val_loss: 2.9000 - val_acc: 0.8400\n",
            "Epoch 891/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0169 - acc: 0.9899 - val_loss: 2.9319 - val_acc: 0.8000\n",
            "Epoch 892/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0271 - acc: 0.9798 - val_loss: 2.9350 - val_acc: 0.8000\n",
            "Epoch 893/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0226 - acc: 0.9899 - val_loss: 2.9391 - val_acc: 0.8000\n",
            "Epoch 894/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0674 - acc: 0.9697 - val_loss: 2.9505 - val_acc: 0.8000\n",
            "Epoch 895/1000\n",
            "99/99 [==============================] - 0s 339us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 2.9561 - val_acc: 0.8000\n",
            "Epoch 896/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0237 - acc: 0.9899 - val_loss: 2.9622 - val_acc: 0.8000\n",
            "Epoch 897/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0284 - acc: 0.9899 - val_loss: 2.9413 - val_acc: 0.8000\n",
            "Epoch 898/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0294 - acc: 0.9899 - val_loss: 2.9124 - val_acc: 0.8400\n",
            "Epoch 899/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0167 - acc: 0.9899 - val_loss: 2.8851 - val_acc: 0.8400\n",
            "Epoch 900/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0239 - acc: 0.9899 - val_loss: 2.8726 - val_acc: 0.8400\n",
            "Epoch 901/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 2.8770 - val_acc: 0.8400\n",
            "Epoch 902/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0391 - acc: 0.9798 - val_loss: 2.9143 - val_acc: 0.8400\n",
            "Epoch 903/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 2.9709 - val_acc: 0.8400\n",
            "Epoch 904/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 3.0193 - val_acc: 0.8000\n",
            "Epoch 905/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 3.0590 - val_acc: 0.8000\n",
            "Epoch 906/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0345 - acc: 0.9798 - val_loss: 3.0949 - val_acc: 0.8000\n",
            "Epoch 907/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0329 - acc: 0.9798 - val_loss: 3.0791 - val_acc: 0.8000\n",
            "Epoch 908/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0148 - acc: 0.9899 - val_loss: 3.0560 - val_acc: 0.8000\n",
            "Epoch 909/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0313 - acc: 0.9798 - val_loss: 3.0165 - val_acc: 0.8000\n",
            "Epoch 910/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0242 - acc: 0.9899 - val_loss: 2.9685 - val_acc: 0.8400\n",
            "Epoch 911/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0221 - acc: 0.9899 - val_loss: 2.9101 - val_acc: 0.8400\n",
            "Epoch 912/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0171 - acc: 0.9899 - val_loss: 2.8648 - val_acc: 0.8400\n",
            "Epoch 913/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0488 - acc: 0.9798 - val_loss: 2.8490 - val_acc: 0.8400\n",
            "Epoch 914/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0316 - acc: 0.9899 - val_loss: 2.8327 - val_acc: 0.8400\n",
            "Epoch 915/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0219 - acc: 0.9899 - val_loss: 2.8131 - val_acc: 0.8400\n",
            "Epoch 916/1000\n",
            "99/99 [==============================] - 0s 365us/sample - loss: 0.0266 - acc: 0.9798 - val_loss: 2.7927 - val_acc: 0.8400\n",
            "Epoch 917/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0478 - acc: 0.9697 - val_loss: 2.7839 - val_acc: 0.8400\n",
            "Epoch 918/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0308 - acc: 0.9798 - val_loss: 2.7967 - val_acc: 0.8400\n",
            "Epoch 919/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0268 - acc: 0.9798 - val_loss: 2.8307 - val_acc: 0.8400\n",
            "Epoch 920/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0380 - acc: 0.9697 - val_loss: 2.8592 - val_acc: 0.8400\n",
            "Epoch 921/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0233 - acc: 0.9798 - val_loss: 2.8852 - val_acc: 0.8400\n",
            "Epoch 922/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0263 - acc: 0.9899 - val_loss: 2.9000 - val_acc: 0.8400\n",
            "Epoch 923/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0293 - acc: 0.9798 - val_loss: 2.8959 - val_acc: 0.8400\n",
            "Epoch 924/1000\n",
            "99/99 [==============================] - 0s 345us/sample - loss: 0.0320 - acc: 0.9899 - val_loss: 2.9196 - val_acc: 0.8400\n",
            "Epoch 925/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0195 - acc: 0.9798 - val_loss: 2.9470 - val_acc: 0.8400\n",
            "Epoch 926/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0328 - acc: 0.9899 - val_loss: 2.9835 - val_acc: 0.8400\n",
            "Epoch 927/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0557 - acc: 0.9697 - val_loss: 2.9993 - val_acc: 0.8400\n",
            "Epoch 928/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0266 - acc: 0.9899 - val_loss: 3.0306 - val_acc: 0.8400\n",
            "Epoch 929/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0377 - acc: 0.9798 - val_loss: 3.0612 - val_acc: 0.8000\n",
            "Epoch 930/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0179 - acc: 0.9899 - val_loss: 3.0887 - val_acc: 0.8000\n",
            "Epoch 931/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0211 - acc: 0.9798 - val_loss: 3.1177 - val_acc: 0.8000\n",
            "Epoch 932/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0279 - acc: 0.9899 - val_loss: 3.1357 - val_acc: 0.8000\n",
            "Epoch 933/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 3.1539 - val_acc: 0.8000\n",
            "Epoch 934/1000\n",
            "99/99 [==============================] - 0s 320us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 3.1720 - val_acc: 0.8000\n",
            "Epoch 935/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0312 - acc: 0.9798 - val_loss: 3.1988 - val_acc: 0.8000\n",
            "Epoch 936/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0258 - acc: 0.9899 - val_loss: 3.2164 - val_acc: 0.8000\n",
            "Epoch 937/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0197 - acc: 0.9899 - val_loss: 3.2290 - val_acc: 0.8000\n",
            "Epoch 938/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0433 - acc: 0.9798 - val_loss: 3.2199 - val_acc: 0.8000\n",
            "Epoch 939/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 3.2226 - val_acc: 0.8000\n",
            "Epoch 940/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0219 - acc: 0.9899 - val_loss: 3.2464 - val_acc: 0.7600\n",
            "Epoch 941/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 3.2385 - val_acc: 0.7600\n",
            "Epoch 942/1000\n",
            "99/99 [==============================] - 0s 326us/sample - loss: 0.0448 - acc: 0.9697 - val_loss: 3.1946 - val_acc: 0.7600\n",
            "Epoch 943/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0272 - acc: 0.9899 - val_loss: 3.1441 - val_acc: 0.8000\n",
            "Epoch 944/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0303 - acc: 0.9899 - val_loss: 3.1005 - val_acc: 0.8400\n",
            "Epoch 945/1000\n",
            "99/99 [==============================] - 0s 308us/sample - loss: 0.0341 - acc: 0.9899 - val_loss: 3.0526 - val_acc: 0.8400\n",
            "Epoch 946/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0182 - acc: 0.9899 - val_loss: 3.0197 - val_acc: 0.8400\n",
            "Epoch 947/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0300 - acc: 0.9798 - val_loss: 3.0184 - val_acc: 0.8400\n",
            "Epoch 948/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0392 - acc: 0.9798 - val_loss: 3.0673 - val_acc: 0.8400\n",
            "Epoch 949/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0235 - acc: 0.9899 - val_loss: 3.1177 - val_acc: 0.8400\n",
            "Epoch 950/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0360 - acc: 0.9798 - val_loss: 3.1892 - val_acc: 0.8400\n",
            "Epoch 951/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0264 - acc: 0.9798 - val_loss: 3.2680 - val_acc: 0.8000\n",
            "Epoch 952/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0202 - acc: 0.9899 - val_loss: 3.3263 - val_acc: 0.8000\n",
            "Epoch 953/1000\n",
            "99/99 [==============================] - 0s 335us/sample - loss: 0.0262 - acc: 0.9798 - val_loss: 3.3358 - val_acc: 0.7600\n",
            "Epoch 954/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0317 - acc: 0.9798 - val_loss: 3.2673 - val_acc: 0.8000\n",
            "Epoch 955/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0237 - acc: 0.9899 - val_loss: 3.1907 - val_acc: 0.8000\n",
            "Epoch 956/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 3.1107 - val_acc: 0.8400\n",
            "Epoch 957/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0308 - acc: 0.9899 - val_loss: 3.0233 - val_acc: 0.8400\n",
            "Epoch 958/1000\n",
            "99/99 [==============================] - 0s 309us/sample - loss: 0.0241 - acc: 0.9899 - val_loss: 2.9496 - val_acc: 0.8400\n",
            "Epoch 959/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0269 - acc: 0.9899 - val_loss: 2.9189 - val_acc: 0.8400\n",
            "Epoch 960/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0455 - acc: 0.9899 - val_loss: 2.9496 - val_acc: 0.8400\n",
            "Epoch 961/1000\n",
            "99/99 [==============================] - 0s 311us/sample - loss: 0.0346 - acc: 0.9798 - val_loss: 3.0000 - val_acc: 0.8400\n",
            "Epoch 962/1000\n",
            "99/99 [==============================] - 0s 318us/sample - loss: 0.0465 - acc: 0.9697 - val_loss: 3.0642 - val_acc: 0.8400\n",
            "Epoch 963/1000\n",
            "99/99 [==============================] - 0s 333us/sample - loss: 0.0168 - acc: 0.9899 - val_loss: 3.1246 - val_acc: 0.8400\n",
            "Epoch 964/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0344 - acc: 0.9798 - val_loss: 3.1515 - val_acc: 0.8000\n",
            "Epoch 965/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0227 - acc: 0.9899 - val_loss: 3.1642 - val_acc: 0.8000\n",
            "Epoch 966/1000\n",
            "99/99 [==============================] - 0s 330us/sample - loss: 0.0260 - acc: 0.9798 - val_loss: 3.1782 - val_acc: 0.8000\n",
            "Epoch 967/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0274 - acc: 0.9899 - val_loss: 3.1624 - val_acc: 0.8000\n",
            "Epoch 968/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0210 - acc: 0.9798 - val_loss: 3.1442 - val_acc: 0.8000\n",
            "Epoch 969/1000\n",
            "99/99 [==============================] - 0s 337us/sample - loss: 0.0294 - acc: 0.9798 - val_loss: 3.1296 - val_acc: 0.8000\n",
            "Epoch 970/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0352 - acc: 0.9798 - val_loss: 3.0706 - val_acc: 0.8400\n",
            "Epoch 971/1000\n",
            "99/99 [==============================] - 0s 316us/sample - loss: 0.0283 - acc: 0.9899 - val_loss: 3.0336 - val_acc: 0.8400\n",
            "Epoch 972/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0217 - acc: 0.9899 - val_loss: 3.0091 - val_acc: 0.8400\n",
            "Epoch 973/1000\n",
            "99/99 [==============================] - 0s 310us/sample - loss: 0.0276 - acc: 0.9798 - val_loss: 2.9871 - val_acc: 0.8400\n",
            "Epoch 974/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0289 - acc: 0.9899 - val_loss: 2.9798 - val_acc: 0.8000\n",
            "Epoch 975/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0344 - acc: 0.9798 - val_loss: 3.0054 - val_acc: 0.8000\n",
            "Epoch 976/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0539 - acc: 0.9697 - val_loss: 2.9054 - val_acc: 0.8000\n",
            "Epoch 977/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0335 - acc: 0.9697 - val_loss: 2.8184 - val_acc: 0.8000\n",
            "Epoch 978/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0413 - acc: 0.9798 - val_loss: 2.7949 - val_acc: 0.8000\n",
            "Epoch 979/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0254 - acc: 0.9899 - val_loss: 2.8216 - val_acc: 0.8000\n",
            "Epoch 980/1000\n",
            "99/99 [==============================] - 0s 327us/sample - loss: 0.0546 - acc: 0.9697 - val_loss: 2.9805 - val_acc: 0.7600\n",
            "Epoch 981/1000\n",
            "99/99 [==============================] - 0s 317us/sample - loss: 0.0410 - acc: 0.9697 - val_loss: 3.1140 - val_acc: 0.7600\n",
            "Epoch 982/1000\n",
            "99/99 [==============================] - 0s 351us/sample - loss: 0.0724 - acc: 0.9798 - val_loss: 3.1681 - val_acc: 0.7600\n",
            "Epoch 983/1000\n",
            "99/99 [==============================] - 0s 346us/sample - loss: 0.0403 - acc: 0.9899 - val_loss: 3.1721 - val_acc: 0.8000\n",
            "Epoch 984/1000\n",
            "99/99 [==============================] - 0s 331us/sample - loss: 0.0411 - acc: 0.9798 - val_loss: 3.1125 - val_acc: 0.8400\n",
            "Epoch 985/1000\n",
            "99/99 [==============================] - 0s 344us/sample - loss: 0.0286 - acc: 0.9899 - val_loss: 3.0619 - val_acc: 0.8400\n",
            "Epoch 986/1000\n",
            "99/99 [==============================] - 0s 336us/sample - loss: 0.0249 - acc: 0.9798 - val_loss: 3.0403 - val_acc: 0.8400\n",
            "Epoch 987/1000\n",
            "99/99 [==============================] - 0s 313us/sample - loss: 0.0278 - acc: 0.9798 - val_loss: 3.0094 - val_acc: 0.8400\n",
            "Epoch 988/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0273 - acc: 0.9798 - val_loss: 3.0214 - val_acc: 0.8400\n",
            "Epoch 989/1000\n",
            "99/99 [==============================] - 0s 312us/sample - loss: 0.0262 - acc: 0.9798 - val_loss: 3.0677 - val_acc: 0.8000\n",
            "Epoch 990/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0261 - acc: 0.9899 - val_loss: 3.0981 - val_acc: 0.8000\n",
            "Epoch 991/1000\n",
            "99/99 [==============================] - 0s 321us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 3.1655 - val_acc: 0.8000\n",
            "Epoch 992/1000\n",
            "99/99 [==============================] - 0s 314us/sample - loss: 0.0279 - acc: 0.9899 - val_loss: 3.2094 - val_acc: 0.7600\n",
            "Epoch 993/1000\n",
            "99/99 [==============================] - 0s 307us/sample - loss: 0.0366 - acc: 0.9899 - val_loss: 3.1761 - val_acc: 0.7600\n",
            "Epoch 994/1000\n",
            "99/99 [==============================] - 0s 325us/sample - loss: 0.0309 - acc: 0.9798 - val_loss: 3.1166 - val_acc: 0.8000\n",
            "Epoch 995/1000\n",
            "99/99 [==============================] - 0s 315us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 3.0616 - val_acc: 0.8000\n",
            "Epoch 996/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0404 - acc: 0.9798 - val_loss: 2.9880 - val_acc: 0.8400\n",
            "Epoch 997/1000\n",
            "99/99 [==============================] - 0s 319us/sample - loss: 0.0393 - acc: 0.9899 - val_loss: 2.9474 - val_acc: 0.8400\n",
            "Epoch 998/1000\n",
            "99/99 [==============================] - 0s 323us/sample - loss: 0.0265 - acc: 0.9798 - val_loss: 2.9106 - val_acc: 0.8400\n",
            "Epoch 999/1000\n",
            "99/99 [==============================] - 0s 322us/sample - loss: 0.0441 - acc: 0.9798 - val_loss: 2.8951 - val_acc: 0.8400\n",
            "Epoch 1000/1000\n",
            "99/99 [==============================] - 0s 324us/sample - loss: 0.0428 - acc: 0.9596 - val_loss: 2.8790 - val_acc: 0.8400\n",
            "Training completed in time:  0:00:36.070698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-C7QG8tkEkH",
        "colab_type": "code",
        "outputId": "88cf3e50-c0a3-402d-d635-110f17c10ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])\n",
        "#model.save('/content/KHA_BAGUS_SOUND.h5')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy:  0.97979796\n",
            "Testing Accuracy:  0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH2-mc_DkOxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buat_prediction(file_name):\n",
        "    prediction_feature = extract_features(file_name) \n",
        "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
        "\n",
        "    predicted_vector = model.predict_classes(prediction_feature)\n",
        "    predicted_class = le.inverse_transform(predicted_vector) \n",
        "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
        "\n",
        "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
        "    predicted_proba = predicted_proba_vector[0]\n",
        "    for i in range(len(predicted_proba)): \n",
        "        category = le.inverse_transform(np.array([i]))\n",
        "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyAHmb5lkPw4",
        "colab_type": "code",
        "outputId": "960b24d6-663c-4068-d515-4792396cfd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "filename = '/content/8SC.wav'\n",
        "buat_prediction(filename)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Algo anda mal:  /content/8SC.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-17fe07aedbd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/8SC.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbuat_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-ff38f23f279e>\u001b[0m in \u001b[0;36mbuat_prediction\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuat_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprediction_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35T6cjfV3FMt",
        "colab_type": "code",
        "outputId": "5dfa0824-5673-4d99-f616-f23bbd95be64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wave\n",
        "import sys\n",
        "\n",
        "\n",
        "spf = wave.open('/content/set_a/Aunlabelledtest__201101220549.wav' , \"r\")\n",
        "#spf = wave.open('/content/Sound/8SC.wav' , \"r\")\n",
        "# Extract Raw Audio from Wav File\n",
        "signal = spf.readframes(-1)\n",
        "signal = np.fromstring(signal, \"Int16\")\n",
        "\n",
        "\n",
        "# If Stereo\n",
        "if spf.getnchannels() == 2:\n",
        "    print(\"Just mono files\")\n",
        "    sys.exit(0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.title(\"Signal Wave...\")\n",
        "plt.plot(signal)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEICAYAAACeSMncAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFLKNQ0iSimlXNMgopRSyrX/D69yrryyCDGAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}